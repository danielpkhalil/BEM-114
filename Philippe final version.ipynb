{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Daniel Khalil: 2205957\n",
    "\n",
    "Philippe Des Boscs: 2176993\n",
    "\n",
    "Christina Liu: 2205359"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import statsmodels.api as sm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Question 1 - Data Cleaning and Summary Statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PERMNO</th>\n",
       "      <th>date</th>\n",
       "      <th>SHRCD</th>\n",
       "      <th>EXCHCD</th>\n",
       "      <th>PRC</th>\n",
       "      <th>RET</th>\n",
       "      <th>SHROUT</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>10000</td>\n",
       "      <td>1986-01-31</td>\n",
       "      <td>10.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>C</td>\n",
       "      <td>3680.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>10000</td>\n",
       "      <td>1986-02-28</td>\n",
       "      <td>10.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-0.257143</td>\n",
       "      <td>3680.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>10000</td>\n",
       "      <td>1986-03-31</td>\n",
       "      <td>10.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.365385</td>\n",
       "      <td>3680.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>10000</td>\n",
       "      <td>1986-04-30</td>\n",
       "      <td>10.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-0.098592</td>\n",
       "      <td>3793.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>10000</td>\n",
       "      <td>1986-05-30</td>\n",
       "      <td>10.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-0.222656</td>\n",
       "      <td>3793.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4705164</th>\n",
       "      <td>93436</td>\n",
       "      <td>2020-08-31</td>\n",
       "      <td>11.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>498.32001</td>\n",
       "      <td>0.741452</td>\n",
       "      <td>931809.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4705165</th>\n",
       "      <td>93436</td>\n",
       "      <td>2020-09-30</td>\n",
       "      <td>11.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>429.01001</td>\n",
       "      <td>-0.139087</td>\n",
       "      <td>948000.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4705166</th>\n",
       "      <td>93436</td>\n",
       "      <td>2020-10-30</td>\n",
       "      <td>11.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>388.04001</td>\n",
       "      <td>-0.095499</td>\n",
       "      <td>947901.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4705167</th>\n",
       "      <td>93436</td>\n",
       "      <td>2020-11-30</td>\n",
       "      <td>11.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>567.59998</td>\n",
       "      <td>0.462736</td>\n",
       "      <td>947901.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4705168</th>\n",
       "      <td>93436</td>\n",
       "      <td>2020-12-31</td>\n",
       "      <td>11.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>705.66998</td>\n",
       "      <td>0.243252</td>\n",
       "      <td>959854.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3630644 rows Ã— 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         PERMNO        date  SHRCD  EXCHCD        PRC        RET    SHROUT\n",
       "1         10000  1986-01-31   10.0     3.0        NaN          C    3680.0\n",
       "2         10000  1986-02-28   10.0     3.0        NaN  -0.257143    3680.0\n",
       "3         10000  1986-03-31   10.0     3.0        NaN   0.365385    3680.0\n",
       "4         10000  1986-04-30   10.0     3.0        NaN  -0.098592    3793.0\n",
       "5         10000  1986-05-30   10.0     3.0        NaN  -0.222656    3793.0\n",
       "...         ...         ...    ...     ...        ...        ...       ...\n",
       "4705164   93436  2020-08-31   11.0     3.0  498.32001   0.741452  931809.0\n",
       "4705165   93436  2020-09-30   11.0     3.0  429.01001  -0.139087  948000.0\n",
       "4705166   93436  2020-10-30   11.0     3.0  388.04001  -0.095499  947901.0\n",
       "4705167   93436  2020-11-30   11.0     3.0  567.59998   0.462736  947901.0\n",
       "4705168   93436  2020-12-31   11.0     3.0  705.66998   0.243252  959854.0\n",
       "\n",
       "[3630644 rows x 7 columns]"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "crsp_data = pd.read_csv('crsp_1926_2020.csv')\n",
    "\n",
    "crsp_data_cleaned = crsp_data[(crsp_data['SHRCD'] == 10) | (crsp_data['SHRCD'] == 11)]\n",
    "crsp_data_cleaned = crsp_data_cleaned[(crsp_data_cleaned['EXCHCD'] == 1) |\n",
    "                                      (crsp_data_cleaned['EXCHCD'] == 2) |\n",
    "                                      (crsp_data_cleaned['EXCHCD'] == 3)]\n",
    "crsp_data_cleaned['PRC'] = crsp_data_cleaned['PRC'].apply(lambda x: x if x >= 0 else np.nan)\n",
    "crsp_data_cleaned"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1200x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "crsp_data_cleaned['date2'] = pd.to_datetime(crsp_data_cleaned['date'], format='%Y-%m-%d')\n",
    "crsp_data_cleaned['year_month'] = crsp_data_cleaned['date2'].dt.to_period('M')\n",
    "crsp_data_cleaned['date'] = np.floor(crsp_data_cleaned['date'].str.replace('-','').astype(float)/100).astype(int)\n",
    "monthly_firms_count = crsp_data_cleaned.groupby('year_month')['PERMNO'].nunique()\n",
    "\n",
    "monthly_firms_count.plot(kind='line', figsize=(12, 6))\n",
    "plt.title('Number of Listed Firms Per Month')\n",
    "plt.xlabel('Year-Month')\n",
    "plt.ylabel('Number of Firms')\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Question 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Part a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Market equity for each stock\n",
    "crsp_data_cleaned['ME'] = (crsp_data_cleaned['PRC'] * crsp_data_cleaned['SHROUT'])/10 # check later\n",
    "\n",
    "# Make decile\n",
    "sortdf = crsp_data_cleaned.drop(['SHRCD', 'EXCHCD', 'PRC', 'SHROUT'], axis=1)\n",
    "sortdf['rank'] = sortdf.groupby('date')['ME'].rank(pct=True)\n",
    "sortdf['decile'] = np.ceil(sortdf['rank']*10)\n",
    "\n",
    "def calc_weights(group):\n",
    "    group['weights_eq'] = 1 / float(group['decile'].count())\n",
    "    group['TME'] = group['ME'].sum()\n",
    "    group['weights_val'] = group['ME'] / group['TME']\n",
    "    return group\n",
    "\n",
    "sortdf = sortdf.groupby(['date', 'decile']).apply(calc_weights)\n",
    "\n",
    "sortdf['decile_lag'] = sortdf.groupby('PERMNO')['decile'].shift(1)\n",
    "sortdf['weights_val_lag'] = sortdf.groupby('PERMNO')['weights_val'].shift(1)\n",
    "sortdf['weights_eq_lag'] = sortdf.groupby('PERMNO')['weights_eq'].shift(1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Part b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean monthly returns for each decile (Equal-weighted):\n",
      "decile_lag\n",
      "date    197306.500000\n",
      "1.0          3.117020\n",
      "2.0          1.502364\n",
      "3.0          1.330793\n",
      "4.0          1.273380\n",
      "5.0          1.262522\n",
      "6.0          1.221263\n",
      "7.0          1.161920\n",
      "8.0          1.091310\n",
      "9.0          1.073214\n",
      "10.0         0.920555\n",
      "dtype: float64\n",
      "Equal-weighted returns are monotonic: True\n",
      "\n",
      "Mean monthly returns for each decile (Value-weighted):\n",
      "decile_lag\n",
      "date    197306.500000\n",
      "1.0          2.478629\n",
      "2.0          1.479960\n",
      "3.0          1.336647\n",
      "4.0          1.268084\n",
      "5.0          1.258483\n",
      "6.0          1.223613\n",
      "7.0          1.159447\n",
      "8.0          1.081011\n",
      "9.0          1.067123\n",
      "10.0         0.910811\n",
      "dtype: float64\n",
      "Value-weighted returns are monotonic: True\n"
     ]
    }
   ],
   "source": [
    "sortdf.reset_index(drop = True, inplace = True)\n",
    "sortdf['RET'] = pd.to_numeric(sortdf['RET'], errors='coerce')\n",
    "\n",
    "sortdf['weighted_val_ret'] = sortdf['weights_val_lag'] * sortdf['RET']\n",
    "sortdf['weighted_eq_ret'] = sortdf['weights_eq_lag'] * sortdf['RET']\n",
    "\n",
    "# Sum up portfolio returns\n",
    "eqports = sortdf.groupby(['date', 'decile_lag'])['weighted_eq_ret'].sum()\n",
    "eqports = eqports.unstack()\n",
    "# Missing accounting data in early years\n",
    "eqports = eqports.dropna(axis=0)\n",
    "# Match data format of FF factors\n",
    "eqports = eqports * 100\n",
    "eqports = eqports.reset_index()\n",
    "\n",
    "valports = sortdf.groupby(['date', 'decile_lag'])['weighted_val_ret'].sum()\n",
    "valports = valports.unstack()\n",
    "valports = valports.dropna(axis=0)\n",
    "valports = valports * 100\n",
    "valports = valports.reset_index()\n",
    "\n",
    "mean_monthly_returns_eq = eqports.mean(axis=0)\n",
    "mean_monthly_returns_val = valports.mean(axis=0)\n",
    "\n",
    "monotonic_eq = (mean_monthly_returns_eq.is_monotonic_increasing or\n",
    "                mean_monthly_returns_eq.is_monotonic_decreasing)\n",
    "\n",
    "monotonic_val = (mean_monthly_returns_val.is_monotonic_increasing or\n",
    "                 mean_monthly_returns_val.is_monotonic_decreasing)\n",
    "\n",
    "print(\"Mean monthly returns for each decile (Equal-weighted):\")\n",
    "print(mean_monthly_returns_eq)\n",
    "print(f\"Equal-weighted returns are monotonic: {monotonic_eq}\\n\")\n",
    "\n",
    "print(\"Mean monthly returns for each decile (Value-weighted):\")\n",
    "print(mean_monthly_returns_val)\n",
    "print(f\"Value-weighted returns are monotonic: {monotonic_val}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Yes, the mean monthly returns for each decile for the equal- and value-weighted portfolios are monotonic. In both cases, the average monthly return decreases as the decile increases. In other word decile 1 has the best average monthly return while decile 10 has the worse."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Equal-Weighted Long-Short Portfolio:\n",
      "Mean Return: 2.196465045619146\n",
      "Volatility: 15.065437159855007\n",
      "Sharpe Ratio: 0.14579497576559441\n",
      "\n",
      "Value-Weighted Long-Short Portfolio:\n",
      "Mean Return: 1.5678189607302107\n",
      "Volatility: 12.93038603178765\n",
      "Sharpe Ratio: 0.12125074664251588\n",
      "\n"
     ]
    }
   ],
   "source": [
    "eqports['1-10'] = eqports[1.0] - eqports[10.0]\n",
    "valports['1-10'] = valports[1.0] - valports[10.0] \n",
    "\n",
    "mean_long_short_eq = eqports['1-10'].mean()\n",
    "mean_long_short_val = valports['1-10'].mean()\n",
    "\n",
    "vol_long_short_eq = eqports['1-10'].std()\n",
    "vol_long_short_val = valports['1-10'].std()\n",
    "\n",
    "sharpe_ratio_eq = mean_long_short_eq / vol_long_short_eq\n",
    "sharpe_ratio_val = mean_long_short_val / vol_long_short_val\n",
    "\n",
    "print(f\"Equal-Weighted Long-Short Portfolio:\")\n",
    "print(f\"Mean Return: {mean_long_short_eq}\")\n",
    "print(f\"Volatility: {vol_long_short_eq}\")\n",
    "print(f\"Sharpe Ratio: {sharpe_ratio_eq}\\n\")\n",
    "\n",
    "print(f\"Value-Weighted Long-Short Portfolio:\")\n",
    "print(f\"Mean Return: {mean_long_short_val}\")\n",
    "print(f\"Volatility: {vol_long_short_val}\")\n",
    "print(f\"Sharpe Ratio: {sharpe_ratio_val}\\n\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Part d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Estimate CAPM - equally weighted portfolio:\n",
      "\n",
      "alpha value: 1.4284969550489417\n",
      "beta value: 1.1613568362950475\n",
      "alpha p-value value: 0.0005434886960075301\n",
      "beta p-value: 1.0774328680137988e-47\n",
      "\n",
      "\n",
      "Estimate CAPM - value weighted portfolio:\n",
      "\n",
      "alpha value: 0.8520223983604259\n",
      "beta value: 1.0679883848088303\n",
      "alpha p-value value: 0.014509506567112062\n",
      "beta p-value: 2.6605356905658286e-55\n"
     ]
    }
   ],
   "source": [
    "ff3 = pd.read_csv('ff3_factors.csv')\n",
    "ff3_merged_eq = pd.merge(eqports, ff3, on='date')\n",
    "ff3_merged_val = pd.merge(valports, ff3, on='date')\n",
    "\n",
    "# Estimate CAPM - equally weighted\n",
    "capm_eq=sm.OLS(ff3_merged_eq['1-10'],\n",
    "              sm.add_constant(ff3_merged_eq[['Mkt-RF']])).fit()\n",
    "\n",
    "alpha = capm_eq.params.iloc[0]\n",
    "beta = capm_eq.params.iloc[1]\n",
    "alpha_pvalue = capm_eq.pvalues.iloc[0]\n",
    "beta_pvalue = capm_eq.pvalues.iloc[1]\n",
    "\n",
    "print('Estimate CAPM - equally weighted portfolio:\\n')\n",
    "print(f'alpha value: {alpha}')\n",
    "print(f'beta value: {beta}')\n",
    "print(f'alpha p-value value: {alpha_pvalue}')\n",
    "print(f'beta p-value: {beta_pvalue}')\n",
    "\n",
    "# Estimate CAPM - value weighted\n",
    "capm_val=sm.OLS(ff3_merged_val['1-10'],\n",
    "              sm.add_constant(ff3_merged_val[['Mkt-RF']])).fit()\n",
    "\n",
    "alpha = capm_val.params.iloc[0]\n",
    "beta = capm_val.params.iloc[1]\n",
    "alpha_pvalue = capm_val.pvalues.iloc[0]\n",
    "beta_pvalue = capm_val.pvalues.iloc[1]\n",
    "\n",
    "print('\\n\\nEstimate CAPM - value weighted portfolio:\\n')\n",
    "print(f'alpha value: {alpha}')\n",
    "print(f'beta value: {beta}')\n",
    "print(f'alpha p-value value: {alpha_pvalue}')\n",
    "print(f'beta p-value: {beta_pvalue}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Estimate FF3 - equally weighted portfolio:\n",
      "\n",
      "alpha value: 0.8849038131408473\n",
      "beta value: 0.4144864644543328\n",
      "alpha p-value value: 0.0024990540943616336\n",
      "beta p-value: 2.235890400005867e-12\n",
      "\n",
      "\n",
      "Estimate FF3 - value weighted portfolio:\n",
      "\n",
      "alpha value: 0.3758447723149844\n",
      "beta value: 0.39901444466792174\n",
      "alpha p-value value: 0.10405540470828431\n",
      "beta p-value: 1.9438340400850038e-17\n"
     ]
    }
   ],
   "source": [
    "# Estimate FF3 - equally weighted\n",
    "ff3_eq=sm.OLS(ff3_merged_eq['1-10'],\n",
    "              sm.add_constant(ff3_merged_eq[['Mkt-RF', 'SMB', 'HML']])).fit()\n",
    "\n",
    "alpha = ff3_eq.params.iloc[0]\n",
    "beta = ff3_eq.params.iloc[1]\n",
    "alpha_pvalue = ff3_eq.pvalues.iloc[0]\n",
    "beta_pvalue = ff3_eq.pvalues.iloc[1]\n",
    "\n",
    "print('Estimate FF3 - equally weighted portfolio:\\n')\n",
    "print(f'alpha value: {alpha}')\n",
    "print(f'beta value: {beta}')\n",
    "print(f'alpha p-value value: {alpha_pvalue}')\n",
    "print(f'beta p-value: {beta_pvalue}')\n",
    "\n",
    "# Estimate FF3 - value weighted\n",
    "ff3_val=sm.OLS(ff3_merged_val['1-10'],\n",
    "              sm.add_constant(ff3_merged_val[['Mkt-RF', 'SMB', 'HML']])).fit()\n",
    "\n",
    "alpha = ff3_val.params.iloc[0]\n",
    "beta = ff3_val.params.iloc[1]\n",
    "alpha_pvalue = ff3_val.pvalues.iloc[0]\n",
    "beta_pvalue = ff3_val.pvalues.iloc[1]\n",
    "\n",
    "print('\\n\\nEstimate FF3 - value weighted portfolio:\\n')\n",
    "print(f'alpha value: {alpha}')\n",
    "print(f'beta value: {beta}')\n",
    "print(f'alpha p-value value: {alpha_pvalue}')\n",
    "print(f'beta p-value: {beta_pvalue}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The CAPM model estimation finds that the equally weighted portfolio has a higher alpha than the value weighted one. The difference is pretty considerable with 1.43 vs 0.85. We notice that the beta value is higher for the value weighted portfolio as well.\n",
    "\n",
    "The FF3 model also finds that the equally weighted portfolio has a higher alpha than the value weighted one. Once again, the difference is pretty considerable with 0.88 vs 0.38. We notice that the beta value is higher for the value weighted portfolio as well."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Part e)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Fama French 1992"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "ff1992_eq = ff3_merged_eq[ff3_merged_eq['date']> 199200].copy()\n",
    "ff1992_val = ff3_merged_val[ff3_merged_val['date']> 199200].copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "CAPM model for both equal and value weighted portfolios"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Estimate CAPM after 1992 - equally weighted portfolio:\n",
      "\n",
      "alpha value: 1.6375023392393535\n",
      "beta value: 0.18511892009748446\n",
      "alpha p-value value: 8.952326586570489e-05\n",
      "beta p-value: 0.049598224547884304\n",
      "\n",
      "\n",
      " Estimate CAPM after 1992 - value weighted portfolio:\n",
      "\n",
      "alpha value: 0.7939763848996699\n",
      "beta value: 0.22260020027709604\n",
      "alpha p-value value: 0.039892015309575514\n",
      "beta p-value: 0.011440649793083093\n"
     ]
    }
   ],
   "source": [
    "capm_eq=sm.OLS(ff1992_eq['1-10'], sm.add_constant(ff1992_eq[['Mkt-RF']])).fit()\n",
    "\n",
    "alpha = capm_eq.params.iloc[0]\n",
    "beta = capm_eq.params.iloc[1]\n",
    "alpha_pvalue = capm_eq.pvalues.iloc[0]\n",
    "beta_pvalue = capm_eq.pvalues.iloc[1]\n",
    "\n",
    "print('Estimate CAPM after 1992 - equally weighted portfolio:\\n')\n",
    "print(f'alpha value: {alpha}')\n",
    "print(f'beta value: {beta}')\n",
    "print(f'alpha p-value value: {alpha_pvalue}')\n",
    "print(f'beta p-value: {beta_pvalue}')\n",
    "\n",
    "capm_val=sm.OLS(ff1992_val['1-10'], sm.add_constant(ff1992_val[['Mkt-RF']])).fit()\n",
    "\n",
    "alpha = capm_val.params.iloc[0]\n",
    "beta = capm_val.params.iloc[1]\n",
    "alpha_pvalue = capm_val.pvalues.iloc[0]\n",
    "beta_pvalue = capm_val.pvalues.iloc[1]\n",
    "\n",
    "print('\\n\\n Estimate CAPM after 1992 - value weighted portfolio:\\n')\n",
    "print(f'alpha value: {alpha}')\n",
    "print(f'beta value: {beta}')\n",
    "print(f'alpha p-value value: {alpha_pvalue}')\n",
    "print(f'beta p-value: {beta_pvalue}')\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "FF3 model for both equal and value weighted portfolios"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Estimate FF3 after 1992 - equally weighted portfolio:\n",
      "\n",
      "alpha value: 1.6172170370912\n",
      "beta value: -0.0024022215993079465\n",
      "alpha p-value value: 2.243428637860019e-05\n",
      "beta p-value: 0.9782939566119688\n",
      "\n",
      "\n",
      " Estimate FF3 after 1992 - value weighted portfolio:\n",
      "\n",
      "alpha value: 0.7525545179970818\n",
      "beta value: 0.013784575767751026\n",
      "alpha p-value value: 0.024010168581136644\n",
      "beta p-value: 0.8595487542932182\n"
     ]
    }
   ],
   "source": [
    "ff3_eq=sm.OLS(ff1992_eq['1-10'], sm.add_constant(ff1992_eq[['Mkt-RF', 'SMB', 'HML']])).fit()\n",
    "\n",
    "alpha = ff3_eq.params.iloc[0]\n",
    "beta = ff3_eq.params.iloc[1]\n",
    "alpha_pvalue = ff3_eq.pvalues.iloc[0]\n",
    "beta_pvalue = ff3_eq.pvalues.iloc[1]\n",
    "\n",
    "print('Estimate FF3 after 1992 - equally weighted portfolio:\\n')\n",
    "print(f'alpha value: {alpha}')\n",
    "print(f'beta value: {beta}')\n",
    "print(f'alpha p-value value: {alpha_pvalue}')\n",
    "print(f'beta p-value: {beta_pvalue}')\n",
    "\n",
    "ff3_val=sm.OLS(ff1992_val['1-10'], sm.add_constant(ff1992_val[['Mkt-RF', 'SMB', 'HML']])).fit()\n",
    "\n",
    "alpha = ff3_val.params.iloc[0]\n",
    "beta = ff3_val.params.iloc[1]\n",
    "alpha_pvalue = ff3_val.pvalues.iloc[0]\n",
    "beta_pvalue = ff3_val.pvalues.iloc[1]\n",
    "\n",
    "print('\\n\\n Estimate FF3 after 1992 - value weighted portfolio:\\n')\n",
    "print(f'alpha value: {alpha}')\n",
    "print(f'beta value: {beta}')\n",
    "print(f'alpha p-value value: {alpha_pvalue}')\n",
    "print(f'beta p-value: {beta_pvalue}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dotcom bubble"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "CAPM model for both equal and value weighted portfolios"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "dc2002_eq = ff3_merged_eq[ff3_merged_eq['date']> 200200].copy()\n",
    "dc2002_val = ff3_merged_val[ff3_merged_val['date']> 200200].copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "CAPM model for both equal and value weighted portfolios"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Estimate CAPM after 2002 - equally weighted portfolio:\n",
      "\n",
      "alpha value: 1.1123500918318416\n",
      "beta value: 0.2782579284026197\n",
      "alpha p-value value: 0.006918957617585194\n",
      "beta p-value: 0.0026101034786650407\n",
      "\n",
      "\n",
      "Estimate CAPM after 2002 - value weighted portfolio:\n",
      "\n",
      "alpha value: 0.47997087227799873\n",
      "beta value: 0.333240995778703\n",
      "alpha p-value value: 0.21353923820900866\n",
      "beta p-value: 0.0001443127135931797\n"
     ]
    }
   ],
   "source": [
    "capm_eq=sm.OLS(dc2002_eq['1-10'], sm.add_constant(dc2002_eq[['Mkt-RF']])).fit()\n",
    "\n",
    "alpha = capm_eq.params.iloc[0]\n",
    "beta = capm_eq.params.iloc[1]\n",
    "alpha_pvalue = capm_eq.pvalues.iloc[0]\n",
    "beta_pvalue = capm_eq.pvalues.iloc[1]\n",
    "\n",
    "print('Estimate CAPM after 2002 - equally weighted portfolio:\\n')\n",
    "print(f'alpha value: {alpha}')\n",
    "print(f'beta value: {beta}')\n",
    "print(f'alpha p-value value: {alpha_pvalue}')\n",
    "print(f'beta p-value: {beta_pvalue}')\n",
    "\n",
    "capm_val=sm.OLS(dc2002_val['1-10'], sm.add_constant(dc2002_val[['Mkt-RF']])).fit()\n",
    "\n",
    "alpha = capm_val.params.iloc[0]\n",
    "beta = capm_val.params.iloc[1]\n",
    "alpha_pvalue = capm_val.pvalues.iloc[0]\n",
    "beta_pvalue = capm_val.pvalues.iloc[1]\n",
    "\n",
    "print('\\n\\nEstimate CAPM after 2002 - value weighted portfolio:\\n')\n",
    "print(f'alpha value: {alpha}')\n",
    "print(f'beta value: {beta}')\n",
    "print(f'alpha p-value value: {alpha_pvalue}')\n",
    "print(f'beta p-value: {beta_pvalue}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "FF3 model for both equal and value weighted portfolios"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Estimate FF3 after 2002 - equally weighted portfolio:\n",
      "\n",
      "alpha value: 1.0468929830810216\n",
      "beta value: 0.11819787835982692\n",
      "alpha p-value value: 0.007814066154051275\n",
      "beta p-value: 0.21036170570376062\n",
      "\n",
      "\n",
      "Estimate FF3 after 2002 - value weighted portfolio:\n",
      "\n",
      "alpha value: 0.4276440200657776\n",
      "beta value: 0.1319436415363685\n",
      "alpha p-value value: 0.22916658805033038\n",
      "beta p-value: 0.12446099759392908\n"
     ]
    }
   ],
   "source": [
    "ff3_eq=sm.OLS(dc2002_eq['1-10'],\n",
    "              sm.add_constant(dc2002_eq[['Mkt-RF', 'SMB', 'HML']])).fit()\n",
    "\n",
    "alpha = ff3_eq.params.iloc[0]\n",
    "beta = ff3_eq.params.iloc[1]\n",
    "alpha_pvalue = ff3_eq.pvalues.iloc[0]\n",
    "beta_pvalue = ff3_eq.pvalues.iloc[1]\n",
    "\n",
    "print('Estimate FF3 after 2002 - equally weighted portfolio:\\n')\n",
    "print(f'alpha value: {alpha}')\n",
    "print(f'beta value: {beta}')\n",
    "print(f'alpha p-value value: {alpha_pvalue}')\n",
    "print(f'beta p-value: {beta_pvalue}')\n",
    "\n",
    "\n",
    "ff3_val=sm.OLS(dc2002_val['1-10'],\n",
    "              sm.add_constant(dc2002_val[['Mkt-RF', 'SMB', 'HML']])).fit()\n",
    "\n",
    "alpha = ff3_val.params.iloc[0]\n",
    "beta = ff3_val.params.iloc[1]\n",
    "alpha_pvalue = ff3_val.pvalues.iloc[0]\n",
    "beta_pvalue = ff3_val.pvalues.iloc[1]\n",
    "\n",
    "print('\\n\\nEstimate FF3 after 2002 - value weighted portfolio:\\n')\n",
    "print(f'alpha value: {alpha}')\n",
    "print(f'beta value: {beta}')\n",
    "print(f'alpha p-value value: {alpha_pvalue}')\n",
    "print(f'beta p-value: {beta_pvalue}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Looking at the CAPM model estimate, the alphas for the equally weighted portfolio have evolved from 1.43 over the entire dataset, to 1.64 after 1992, and to 1.11 after 2002. It's interesting to see that the period with the highest alpha is from 1992 when the Fama French paper was published. Perhaps, many people followed that strategy after its publication leading to an overall movement in the market that drove up the price of selected stocks. The dotcom bubble seems to have negatively impacted that strategy though as past that point, the alpha is only 1.11. It still remains very good though which suggests that size still works indeed!\n",
    "\n",
    "Looking at the CAPM model estimate, the alphas for the value weighted portfolio have evolved from 0.38 over the entire dataset, to 0.79 after 1992, and to 0.48 after 2002. We observe the same pattern across time as for the equal weighted portfolio. The dotcom bubble seems to have negatively impacted that strategy though as past that point, the alpha is only 0.48. It still remains decently good though which once again goes in the favor of size.\n",
    "\n",
    "Looking at the FF3 model estimate, the alphas for the equally weighted portfolio have evolved from 0.88 over the entire dataset, to 1.62 after 1992, and to 1.04 after 2002. This remains very similar to what we saw with the CAPM estimate. We notice though that after the dotcom bubble burst, the alpha is higher than it is over the entire dataset. The alpha still remains relatively high suggesting yet again that size still works (at least past 2002).\n",
    "\n",
    "Finally, looking at the FF3 model estimate, the alphas for the value weighted portfolio have evolved from 0.38 over the entire dataset, to 0.75 after 1992, and to 0.43 after 2002. This is also very similar to what we saw with the CAPM estimate. The alpha remains relatively high suggesting yet again that size still works."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Question 3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Part a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert 'RET' column to numeric, turning non-numeric values into NaN\n",
    "crsp_data_cleaned['RET'] = pd.to_numeric(crsp_data_cleaned['RET'], errors='coerce')\n",
    "\n",
    "# Now you can calculate the rolling cumulative returns\n",
    "crsp_data_cleaned['cumulative_returns'] = crsp_data_cleaned.groupby('PERMNO')['RET'].rolling(window=11, min_periods=11).apply(lambda x: np.prod(1+x)-1, raw=True).shift(2).reset_index(0,drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make decile\n",
    "sortdf = crsp_data_cleaned.drop(['SHRCD', 'EXCHCD', 'PRC', 'SHROUT'], axis=1)\n",
    "sortdf['rank'] = sortdf.groupby('date')['cumulative_returns'].rank(pct=True)\n",
    "sortdf['decile'] = np.ceil(sortdf['rank']*10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PERMNO</th>\n",
       "      <th>date</th>\n",
       "      <th>RET</th>\n",
       "      <th>date2</th>\n",
       "      <th>year_month</th>\n",
       "      <th>ME</th>\n",
       "      <th>cumulative_returns</th>\n",
       "      <th>rank</th>\n",
       "      <th>decile</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>10000</td>\n",
       "      <td>198601</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1986-01-31</td>\n",
       "      <td>1986-01</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>10000</td>\n",
       "      <td>198602</td>\n",
       "      <td>-0.257143</td>\n",
       "      <td>1986-02-28</td>\n",
       "      <td>1986-02</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>10000</td>\n",
       "      <td>198603</td>\n",
       "      <td>0.365385</td>\n",
       "      <td>1986-03-31</td>\n",
       "      <td>1986-03</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>10000</td>\n",
       "      <td>198604</td>\n",
       "      <td>-0.098592</td>\n",
       "      <td>1986-04-30</td>\n",
       "      <td>1986-04</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>10000</td>\n",
       "      <td>198605</td>\n",
       "      <td>-0.222656</td>\n",
       "      <td>1986-05-30</td>\n",
       "      <td>1986-05</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4705164</th>\n",
       "      <td>93436</td>\n",
       "      <td>202008</td>\n",
       "      <td>0.741452</td>\n",
       "      <td>2020-08-31</td>\n",
       "      <td>2020-08</td>\n",
       "      <td>4.643391e+07</td>\n",
       "      <td>5.341741</td>\n",
       "      <td>0.993531</td>\n",
       "      <td>10.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4705165</th>\n",
       "      <td>93436</td>\n",
       "      <td>202009</td>\n",
       "      <td>-0.139087</td>\n",
       "      <td>2020-09-30</td>\n",
       "      <td>2020-09</td>\n",
       "      <td>4.067015e+07</td>\n",
       "      <td>9.344169</td>\n",
       "      <td>0.998825</td>\n",
       "      <td>10.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4705166</th>\n",
       "      <td>93436</td>\n",
       "      <td>202010</td>\n",
       "      <td>-0.095499</td>\n",
       "      <td>2020-10-30</td>\n",
       "      <td>2020-10</td>\n",
       "      <td>3.678235e+07</td>\n",
       "      <td>5.811416</td>\n",
       "      <td>0.995022</td>\n",
       "      <td>10.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4705167</th>\n",
       "      <td>93436</td>\n",
       "      <td>202011</td>\n",
       "      <td>0.462736</td>\n",
       "      <td>2020-11-30</td>\n",
       "      <td>2020-11</td>\n",
       "      <td>5.380286e+07</td>\n",
       "      <td>4.880464</td>\n",
       "      <td>0.994435</td>\n",
       "      <td>10.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4705168</th>\n",
       "      <td>93436</td>\n",
       "      <td>202012</td>\n",
       "      <td>0.243252</td>\n",
       "      <td>2020-12-31</td>\n",
       "      <td>2020-12</td>\n",
       "      <td>6.773402e+07</td>\n",
       "      <td>5.784121</td>\n",
       "      <td>0.991511</td>\n",
       "      <td>10.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3630644 rows Ã— 9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         PERMNO    date       RET      date2 year_month            ME  \\\n",
       "1         10000  198601       NaN 1986-01-31    1986-01           NaN   \n",
       "2         10000  198602 -0.257143 1986-02-28    1986-02           NaN   \n",
       "3         10000  198603  0.365385 1986-03-31    1986-03           NaN   \n",
       "4         10000  198604 -0.098592 1986-04-30    1986-04           NaN   \n",
       "5         10000  198605 -0.222656 1986-05-30    1986-05           NaN   \n",
       "...         ...     ...       ...        ...        ...           ...   \n",
       "4705164   93436  202008  0.741452 2020-08-31    2020-08  4.643391e+07   \n",
       "4705165   93436  202009 -0.139087 2020-09-30    2020-09  4.067015e+07   \n",
       "4705166   93436  202010 -0.095499 2020-10-30    2020-10  3.678235e+07   \n",
       "4705167   93436  202011  0.462736 2020-11-30    2020-11  5.380286e+07   \n",
       "4705168   93436  202012  0.243252 2020-12-31    2020-12  6.773402e+07   \n",
       "\n",
       "         cumulative_returns      rank  decile  \n",
       "1                       NaN       NaN     NaN  \n",
       "2                       NaN       NaN     NaN  \n",
       "3                       NaN       NaN     NaN  \n",
       "4                       NaN       NaN     NaN  \n",
       "5                       NaN       NaN     NaN  \n",
       "...                     ...       ...     ...  \n",
       "4705164            5.341741  0.993531    10.0  \n",
       "4705165            9.344169  0.998825    10.0  \n",
       "4705166            5.811416  0.995022    10.0  \n",
       "4705167            4.880464  0.994435    10.0  \n",
       "4705168            5.784121  0.991511    10.0  \n",
       "\n",
       "[3630644 rows x 9 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "sortdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Form the equal- and value-weighted portfolios for the ten momentum portfolios\n",
    "def calc_weights(group):\n",
    "    group['weights_eq'] = 1 / float(group['decile'].count())\n",
    "    group['TME'] = group['ME'].sum()\n",
    "    group['weights_val'] = group['ME'] / group['TME']\n",
    "    return group\n",
    "\n",
    "sortdf = sortdf.groupby(['date', 'decile']).apply(calc_weights)\n",
    "\n",
    "sortdf['decile_lag'] = sortdf.groupby('PERMNO')['decile'].shift(1)\n",
    "sortdf['weights_val_lag'] = sortdf.groupby('PERMNO')['weights_val'].shift(1)\n",
    "sortdf['weights_eq_lag'] = sortdf.groupby('PERMNO')['weights_eq'].shift(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>PERMNO</th>\n",
       "      <th>date</th>\n",
       "      <th>RET</th>\n",
       "      <th>date2</th>\n",
       "      <th>year_month</th>\n",
       "      <th>ME</th>\n",
       "      <th>cumulative_returns</th>\n",
       "      <th>rank</th>\n",
       "      <th>decile</th>\n",
       "      <th>weights_eq</th>\n",
       "      <th>TME</th>\n",
       "      <th>weights_val</th>\n",
       "      <th>decile_lag</th>\n",
       "      <th>weights_val_lag</th>\n",
       "      <th>weights_eq_lag</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>date</th>\n",
       "      <th>decile</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"5\" valign=\"top\">192611</th>\n",
       "      <th rowspan=\"5\" valign=\"top\">1.0</th>\n",
       "      <th>9832</th>\n",
       "      <td>10057</td>\n",
       "      <td>192611</td>\n",
       "      <td>-0.316239</td>\n",
       "      <td>1926-11-30</td>\n",
       "      <td>1926-11</td>\n",
       "      <td>2.500000e+02</td>\n",
       "      <td>-0.591837</td>\n",
       "      <td>0.036036</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.022727</td>\n",
       "      <td>2.641839e+04</td>\n",
       "      <td>0.009463</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32357</th>\n",
       "      <td>10188</td>\n",
       "      <td>192611</td>\n",
       "      <td>-0.097222</td>\n",
       "      <td>1926-11-30</td>\n",
       "      <td>1926-11</td>\n",
       "      <td>3.363750e+02</td>\n",
       "      <td>-0.503816</td>\n",
       "      <td>0.063063</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.022727</td>\n",
       "      <td>2.641839e+04</td>\n",
       "      <td>0.012733</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33968</th>\n",
       "      <td>10196</td>\n",
       "      <td>192611</td>\n",
       "      <td>0.137931</td>\n",
       "      <td>1926-11-30</td>\n",
       "      <td>1926-11</td>\n",
       "      <td>1.518000e+03</td>\n",
       "      <td>-0.604790</td>\n",
       "      <td>0.029279</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.022727</td>\n",
       "      <td>2.641839e+04</td>\n",
       "      <td>0.057460</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36184</th>\n",
       "      <td>10209</td>\n",
       "      <td>192611</td>\n",
       "      <td>0.353659</td>\n",
       "      <td>1926-11-30</td>\n",
       "      <td>1926-11</td>\n",
       "      <td>4.620375e+02</td>\n",
       "      <td>-0.476416</td>\n",
       "      <td>0.081081</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.022727</td>\n",
       "      <td>2.641839e+04</td>\n",
       "      <td>0.017489</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>87182</th>\n",
       "      <td>10524</td>\n",
       "      <td>192611</td>\n",
       "      <td>0.085271</td>\n",
       "      <td>1926-11-30</td>\n",
       "      <td>1926-11</td>\n",
       "      <td>1.750000e+03</td>\n",
       "      <td>-0.469698</td>\n",
       "      <td>0.090090</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.022727</td>\n",
       "      <td>2.641839e+04</td>\n",
       "      <td>0.066242</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <th>...</th>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"5\" valign=\"top\">202012</th>\n",
       "      <th rowspan=\"5\" valign=\"top\">10.0</th>\n",
       "      <th>4689308</th>\n",
       "      <td>93263</td>\n",
       "      <td>202012</td>\n",
       "      <td>0.560000</td>\n",
       "      <td>2020-12-31</td>\n",
       "      <td>2020-12</td>\n",
       "      <td>3.635552e+05</td>\n",
       "      <td>8.316665</td>\n",
       "      <td>0.997368</td>\n",
       "      <td>10.0</td>\n",
       "      <td>0.002924</td>\n",
       "      <td>2.587657e+08</td>\n",
       "      <td>0.001405</td>\n",
       "      <td>10.0</td>\n",
       "      <td>0.000804</td>\n",
       "      <td>0.002924</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4690300</th>\n",
       "      <td>93272</td>\n",
       "      <td>202012</td>\n",
       "      <td>0.256757</td>\n",
       "      <td>2020-12-31</td>\n",
       "      <td>2020-12</td>\n",
       "      <td>1.838364e+05</td>\n",
       "      <td>2.248915</td>\n",
       "      <td>0.961696</td>\n",
       "      <td>10.0</td>\n",
       "      <td>0.002924</td>\n",
       "      <td>2.587657e+08</td>\n",
       "      <td>0.000710</td>\n",
       "      <td>10.0</td>\n",
       "      <td>0.000509</td>\n",
       "      <td>0.002924</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4691300</th>\n",
       "      <td>93285</td>\n",
       "      <td>202012</td>\n",
       "      <td>0.377810</td>\n",
       "      <td>2020-12-31</td>\n",
       "      <td>2020-12</td>\n",
       "      <td>1.170499e+04</td>\n",
       "      <td>1.842183</td>\n",
       "      <td>0.950292</td>\n",
       "      <td>10.0</td>\n",
       "      <td>0.002924</td>\n",
       "      <td>2.587657e+08</td>\n",
       "      <td>0.000045</td>\n",
       "      <td>9.0</td>\n",
       "      <td>0.000011</td>\n",
       "      <td>0.002933</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4701611</th>\n",
       "      <td>93393</td>\n",
       "      <td>202012</td>\n",
       "      <td>0.091997</td>\n",
       "      <td>2020-12-31</td>\n",
       "      <td>2020-12</td>\n",
       "      <td>1.050616e+05</td>\n",
       "      <td>1.708718</td>\n",
       "      <td>0.943567</td>\n",
       "      <td>10.0</td>\n",
       "      <td>0.002924</td>\n",
       "      <td>2.587657e+08</td>\n",
       "      <td>0.000406</td>\n",
       "      <td>10.0</td>\n",
       "      <td>0.000334</td>\n",
       "      <td>0.002924</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4705168</th>\n",
       "      <td>93436</td>\n",
       "      <td>202012</td>\n",
       "      <td>0.243252</td>\n",
       "      <td>2020-12-31</td>\n",
       "      <td>2020-12</td>\n",
       "      <td>6.773402e+07</td>\n",
       "      <td>4.423475</td>\n",
       "      <td>0.989181</td>\n",
       "      <td>10.0</td>\n",
       "      <td>0.002924</td>\n",
       "      <td>2.587657e+08</td>\n",
       "      <td>0.261758</td>\n",
       "      <td>10.0</td>\n",
       "      <td>0.187239</td>\n",
       "      <td>0.002924</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3279165 rows Ã— 15 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                       PERMNO    date       RET      date2 year_month  \\\n",
       "date   decile                                                           \n",
       "192611 1.0    9832      10057  192611 -0.316239 1926-11-30    1926-11   \n",
       "              32357     10188  192611 -0.097222 1926-11-30    1926-11   \n",
       "              33968     10196  192611  0.137931 1926-11-30    1926-11   \n",
       "              36184     10209  192611  0.353659 1926-11-30    1926-11   \n",
       "              87182     10524  192611  0.085271 1926-11-30    1926-11   \n",
       "...                       ...     ...       ...        ...        ...   \n",
       "202012 10.0   4689308   93263  202012  0.560000 2020-12-31    2020-12   \n",
       "              4690300   93272  202012  0.256757 2020-12-31    2020-12   \n",
       "              4691300   93285  202012  0.377810 2020-12-31    2020-12   \n",
       "              4701611   93393  202012  0.091997 2020-12-31    2020-12   \n",
       "              4705168   93436  202012  0.243252 2020-12-31    2020-12   \n",
       "\n",
       "                                 ME  cumulative_returns      rank  decile  \\\n",
       "date   decile                                                               \n",
       "192611 1.0    9832     2.500000e+02           -0.591837  0.036036     1.0   \n",
       "              32357    3.363750e+02           -0.503816  0.063063     1.0   \n",
       "              33968    1.518000e+03           -0.604790  0.029279     1.0   \n",
       "              36184    4.620375e+02           -0.476416  0.081081     1.0   \n",
       "              87182    1.750000e+03           -0.469698  0.090090     1.0   \n",
       "...                             ...                 ...       ...     ...   \n",
       "202012 10.0   4689308  3.635552e+05            8.316665  0.997368    10.0   \n",
       "              4690300  1.838364e+05            2.248915  0.961696    10.0   \n",
       "              4691300  1.170499e+04            1.842183  0.950292    10.0   \n",
       "              4701611  1.050616e+05            1.708718  0.943567    10.0   \n",
       "              4705168  6.773402e+07            4.423475  0.989181    10.0   \n",
       "\n",
       "                       weights_eq           TME  weights_val  decile_lag  \\\n",
       "date   decile                                                              \n",
       "192611 1.0    9832       0.022727  2.641839e+04     0.009463         NaN   \n",
       "              32357      0.022727  2.641839e+04     0.012733         NaN   \n",
       "              33968      0.022727  2.641839e+04     0.057460         NaN   \n",
       "              36184      0.022727  2.641839e+04     0.017489         NaN   \n",
       "              87182      0.022727  2.641839e+04     0.066242         NaN   \n",
       "...                           ...           ...          ...         ...   \n",
       "202012 10.0   4689308    0.002924  2.587657e+08     0.001405        10.0   \n",
       "              4690300    0.002924  2.587657e+08     0.000710        10.0   \n",
       "              4691300    0.002924  2.587657e+08     0.000045         9.0   \n",
       "              4701611    0.002924  2.587657e+08     0.000406        10.0   \n",
       "              4705168    0.002924  2.587657e+08     0.261758        10.0   \n",
       "\n",
       "                       weights_val_lag  weights_eq_lag  \n",
       "date   decile                                           \n",
       "192611 1.0    9832                 NaN             NaN  \n",
       "              32357                NaN             NaN  \n",
       "              33968                NaN             NaN  \n",
       "              36184                NaN             NaN  \n",
       "              87182                NaN             NaN  \n",
       "...                                ...             ...  \n",
       "202012 10.0   4689308         0.000804        0.002924  \n",
       "              4690300         0.000509        0.002924  \n",
       "              4691300         0.000011        0.002933  \n",
       "              4701611         0.000334        0.002924  \n",
       "              4705168         0.187239        0.002924  \n",
       "\n",
       "[3279165 rows x 15 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "sortdf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Part b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean monthly returns for each decile (Equal-weighted):\n",
      "decile_lag\n",
      "date    197352.287865\n",
      "1.0          1.144305\n",
      "2.0          1.064822\n",
      "3.0          1.217383\n",
      "4.0          1.170327\n",
      "5.0          1.219944\n",
      "6.0          1.303896\n",
      "7.0          1.410952\n",
      "8.0          1.440834\n",
      "9.0          1.539089\n",
      "10.0         1.744611\n",
      "dtype: float64\n",
      "Equal-weighted returns are monotonic: False\n",
      "\n",
      "Mean monthly returns for each decile (Value-weighted):\n",
      "decile_lag\n",
      "date    197352.287865\n",
      "1.0          0.228607\n",
      "2.0          0.533213\n",
      "3.0          0.782392\n",
      "4.0          0.903838\n",
      "5.0          0.927468\n",
      "6.0          0.973006\n",
      "7.0          1.068319\n",
      "8.0          1.155728\n",
      "9.0          1.235009\n",
      "10.0         1.479964\n",
      "dtype: float64\n",
      "Value-weighted returns are monotonic: False\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>decile_lag</th>\n",
       "      <th>date</th>\n",
       "      <th>1.0</th>\n",
       "      <th>2.0</th>\n",
       "      <th>3.0</th>\n",
       "      <th>4.0</th>\n",
       "      <th>5.0</th>\n",
       "      <th>6.0</th>\n",
       "      <th>7.0</th>\n",
       "      <th>8.0</th>\n",
       "      <th>9.0</th>\n",
       "      <th>10.0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>192601</td>\n",
       "      <td>0.001209</td>\n",
       "      <td>1.649523</td>\n",
       "      <td>0.407028</td>\n",
       "      <td>0.878536</td>\n",
       "      <td>1.416923</td>\n",
       "      <td>4.211967</td>\n",
       "      <td>-0.593649</td>\n",
       "      <td>1.557935</td>\n",
       "      <td>-0.237902</td>\n",
       "      <td>1.934547</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>192701</td>\n",
       "      <td>0.375342</td>\n",
       "      <td>-9.314924</td>\n",
       "      <td>7.988318</td>\n",
       "      <td>5.855666</td>\n",
       "      <td>1.500217</td>\n",
       "      <td>8.741004</td>\n",
       "      <td>-3.039191</td>\n",
       "      <td>0.567937</td>\n",
       "      <td>-0.213094</td>\n",
       "      <td>0.168475</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>192702</td>\n",
       "      <td>5.429484</td>\n",
       "      <td>6.045233</td>\n",
       "      <td>14.772018</td>\n",
       "      <td>26.628656</td>\n",
       "      <td>6.068283</td>\n",
       "      <td>5.879763</td>\n",
       "      <td>3.624080</td>\n",
       "      <td>5.895644</td>\n",
       "      <td>5.496386</td>\n",
       "      <td>5.259776</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>192703</td>\n",
       "      <td>-10.764280</td>\n",
       "      <td>-3.066426</td>\n",
       "      <td>2.790509</td>\n",
       "      <td>-2.690691</td>\n",
       "      <td>-6.627557</td>\n",
       "      <td>-1.865443</td>\n",
       "      <td>-15.965384</td>\n",
       "      <td>-0.490007</td>\n",
       "      <td>20.923493</td>\n",
       "      <td>3.651683</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>192704</td>\n",
       "      <td>0.708904</td>\n",
       "      <td>-9.864522</td>\n",
       "      <td>-0.692226</td>\n",
       "      <td>2.751067</td>\n",
       "      <td>-0.319615</td>\n",
       "      <td>-5.386724</td>\n",
       "      <td>1.436915</td>\n",
       "      <td>-0.911465</td>\n",
       "      <td>-2.914733</td>\n",
       "      <td>4.136957</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1124</th>\n",
       "      <td>202008</td>\n",
       "      <td>3.599718</td>\n",
       "      <td>5.094813</td>\n",
       "      <td>6.928604</td>\n",
       "      <td>4.340953</td>\n",
       "      <td>6.657829</td>\n",
       "      <td>4.595906</td>\n",
       "      <td>5.090737</td>\n",
       "      <td>4.312206</td>\n",
       "      <td>3.172607</td>\n",
       "      <td>3.541746</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1125</th>\n",
       "      <td>202009</td>\n",
       "      <td>-6.160866</td>\n",
       "      <td>-4.422428</td>\n",
       "      <td>-3.312075</td>\n",
       "      <td>-3.005215</td>\n",
       "      <td>-2.547669</td>\n",
       "      <td>-2.118888</td>\n",
       "      <td>-2.465467</td>\n",
       "      <td>-1.957995</td>\n",
       "      <td>-1.442655</td>\n",
       "      <td>0.558763</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1126</th>\n",
       "      <td>202010</td>\n",
       "      <td>-2.315287</td>\n",
       "      <td>3.229721</td>\n",
       "      <td>4.299260</td>\n",
       "      <td>2.142781</td>\n",
       "      <td>2.828298</td>\n",
       "      <td>1.945891</td>\n",
       "      <td>1.904596</td>\n",
       "      <td>0.000267</td>\n",
       "      <td>0.726221</td>\n",
       "      <td>-2.216531</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1127</th>\n",
       "      <td>202011</td>\n",
       "      <td>38.188981</td>\n",
       "      <td>23.794518</td>\n",
       "      <td>20.576148</td>\n",
       "      <td>19.699745</td>\n",
       "      <td>16.514408</td>\n",
       "      <td>16.663575</td>\n",
       "      <td>17.467311</td>\n",
       "      <td>15.855039</td>\n",
       "      <td>14.682045</td>\n",
       "      <td>20.481395</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1128</th>\n",
       "      <td>202012</td>\n",
       "      <td>17.309223</td>\n",
       "      <td>11.834926</td>\n",
       "      <td>7.774695</td>\n",
       "      <td>8.120109</td>\n",
       "      <td>8.507148</td>\n",
       "      <td>7.608044</td>\n",
       "      <td>7.853300</td>\n",
       "      <td>6.831219</td>\n",
       "      <td>8.036585</td>\n",
       "      <td>8.008666</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1129 rows Ã— 11 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "decile_lag    date        1.0        2.0        3.0        4.0        5.0  \\\n",
       "0           192601   0.001209   1.649523   0.407028   0.878536   1.416923   \n",
       "1           192701   0.375342  -9.314924   7.988318   5.855666   1.500217   \n",
       "2           192702   5.429484   6.045233  14.772018  26.628656   6.068283   \n",
       "3           192703 -10.764280  -3.066426   2.790509  -2.690691  -6.627557   \n",
       "4           192704   0.708904  -9.864522  -0.692226   2.751067  -0.319615   \n",
       "...            ...        ...        ...        ...        ...        ...   \n",
       "1124        202008   3.599718   5.094813   6.928604   4.340953   6.657829   \n",
       "1125        202009  -6.160866  -4.422428  -3.312075  -3.005215  -2.547669   \n",
       "1126        202010  -2.315287   3.229721   4.299260   2.142781   2.828298   \n",
       "1127        202011  38.188981  23.794518  20.576148  19.699745  16.514408   \n",
       "1128        202012  17.309223  11.834926   7.774695   8.120109   8.507148   \n",
       "\n",
       "decile_lag        6.0        7.0        8.0        9.0       10.0  \n",
       "0            4.211967  -0.593649   1.557935  -0.237902   1.934547  \n",
       "1            8.741004  -3.039191   0.567937  -0.213094   0.168475  \n",
       "2            5.879763   3.624080   5.895644   5.496386   5.259776  \n",
       "3           -1.865443 -15.965384  -0.490007  20.923493   3.651683  \n",
       "4           -5.386724   1.436915  -0.911465  -2.914733   4.136957  \n",
       "...               ...        ...        ...        ...        ...  \n",
       "1124         4.595906   5.090737   4.312206   3.172607   3.541746  \n",
       "1125        -2.118888  -2.465467  -1.957995  -1.442655   0.558763  \n",
       "1126         1.945891   1.904596   0.000267   0.726221  -2.216531  \n",
       "1127        16.663575  17.467311  15.855039  14.682045  20.481395  \n",
       "1128         7.608044   7.853300   6.831219   8.036585   8.008666  \n",
       "\n",
       "[1129 rows x 11 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "sortdf.reset_index(drop = True, inplace = True)\n",
    "sortdf['weighted_val_lag'] = sortdf['weights_val_lag'] * sortdf['RET']\n",
    "sortdf['weighted_eq_lag'] = sortdf['weights_eq_lag'] * sortdf['RET']\n",
    "\n",
    "# Sum up portfolio returns\n",
    "eqports = sortdf.groupby(['date', 'decile_lag'])['weighted_eq_lag'].sum()\n",
    "eqports = eqports.unstack()\n",
    "# Missing accounting data in early years\n",
    "eqports = eqports.dropna(axis=0)\n",
    "# Match data format of FF factors\n",
    "eqports = eqports * 100\n",
    "eqports = eqports.reset_index()\n",
    "\n",
    "valports = sortdf.groupby(['date', 'decile_lag'])['weighted_val_lag'].sum()\n",
    "valports = valports.unstack()\n",
    "valports = valports.dropna(axis=0)\n",
    "valports = valports * 100\n",
    "valports = valports.reset_index()\n",
    "\n",
    "mean_monthly_returns_eq = eqports.mean(axis=0)\n",
    "mean_monthly_returns_val = valports.mean(axis=0)\n",
    "\n",
    "monotonic_eq = (mean_monthly_returns_eq.is_monotonic_increasing or\n",
    "                mean_monthly_returns_eq.is_monotonic_decreasing)\n",
    "\n",
    "monotonic_val = (mean_monthly_returns_val.is_monotonic_increasing or\n",
    "                 mean_monthly_returns_val.is_monotonic_decreasing)\n",
    "\n",
    "print(\"Mean monthly returns for each decile (Equal-weighted):\")\n",
    "print(mean_monthly_returns_eq)\n",
    "print(f\"Equal-weighted returns are monotonic: {monotonic_eq}\\n\")\n",
    "\n",
    "print(\"Mean monthly returns for each decile (Value-weighted):\")\n",
    "print(mean_monthly_returns_val)\n",
    "print(f\"Value-weighted returns are monotonic: {monotonic_val}\")\n",
    "\n",
    "eqports"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Part c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Equal-Weighted Long-Short Portfolio:\n",
      "Mean Return: 0.6003058776220164\n",
      "Volatility: 8.071971118712762\n",
      "Sharpe Ratio: 0.07436918056239865\n",
      "\n",
      "Value-Weighted Long-Short Portfolio:\n",
      "Mean Return: 1.2513567758419675\n",
      "Volatility: 8.47887052551482\n",
      "Sharpe Ratio: 0.14758531482186865\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Form the long-short winners-minus-losers portfolio\n",
    "eqports['10-1'] = eqports[10.0] - eqports[1.0]\n",
    "valports['10-1'] = valports[10.0] - valports[1.0] \n",
    "\n",
    "mean_long_short_eq = eqports['10-1'].mean()\n",
    "mean_long_short_val = valports['10-1'].mean()\n",
    "\n",
    "vol_long_short_eq = eqports['10-1'].std()\n",
    "vol_long_short_val = valports['10-1'].std()\n",
    "\n",
    "sharpe_ratio_eq = mean_long_short_eq / vol_long_short_eq\n",
    "sharpe_ratio_val = mean_long_short_val / vol_long_short_val\n",
    "\n",
    "print(f\"Equal-Weighted Long-Short Portfolio:\")\n",
    "print(f\"Mean Return: {mean_long_short_eq}\")\n",
    "print(f\"Volatility: {vol_long_short_eq}\")\n",
    "print(f\"Sharpe Ratio: {sharpe_ratio_eq}\\n\")\n",
    "\n",
    "print(f\"Value-Weighted Long-Short Portfolio:\")\n",
    "print(f\"Mean Return: {mean_long_short_val}\")\n",
    "print(f\"Volatility: {vol_long_short_val}\")\n",
    "print(f\"Sharpe Ratio: {sharpe_ratio_val}\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Part d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                            OLS Regression Results                            \n",
      "==============================================================================\n",
      "Dep. Variable:                   10-1   R-squared:                       0.076\n",
      "Model:                            OLS   Adj. R-squared:                  0.076\n",
      "Method:                 Least Squares   F-statistic:                     93.15\n",
      "Date:                Sun, 21 Apr 2024   Prob (F-statistic):           3.13e-21\n",
      "Time:                        22:26:09   Log-Likelihood:                -3911.4\n",
      "No. Observations:                1128   AIC:                             7827.\n",
      "Df Residuals:                    1126   BIC:                             7837.\n",
      "Df Model:                           1                                         \n",
      "Covariance Type:            nonrobust                                         \n",
      "==============================================================================\n",
      "                 coef    std err          t      P>|t|      [0.025      0.975]\n",
      "------------------------------------------------------------------------------\n",
      "const          0.8812      0.233      3.782      0.000       0.424       1.338\n",
      "Mkt-RF        -0.4160      0.043     -9.652      0.000      -0.501      -0.331\n",
      "==============================================================================\n",
      "Omnibus:                      833.321   Durbin-Watson:                   2.116\n",
      "Prob(Omnibus):                  0.000   Jarque-Bera (JB):            31274.371\n",
      "Skew:                          -2.968   Prob(JB):                         0.00\n",
      "Kurtosis:                      28.103   Cond. No.                         5.45\n",
      "==============================================================================\n",
      "\n",
      "Notes:\n",
      "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n"
     ]
    }
   ],
   "source": [
    "ff3 = pd.read_csv('ff3_factors.csv')\n",
    "ff5 = pd.read_csv('ff5_factors.csv')\n",
    "#make Date into date\n",
    "ff3.rename(columns={'Date': 'date'}, inplace=True)\n",
    "ff5.rename(columns={'Date': 'date'}, inplace=True)\n",
    "ff3_merged_eq = pd.merge(eqports, ff3, on='date')\n",
    "ff3_merged_val = pd.merge(valports, ff3, on='date')\n",
    "ff5_merged_eq = pd.merge(eqports, ff5, on='date')\n",
    "ff5_merged_val = pd.merge(valports, ff5, on='date')\n",
    "\n",
    "# Estimate CAPM - equally weighted\n",
    "model1=sm.OLS(ff3_merged_eq['10-1'],\n",
    "              sm.add_constant(ff3_merged_eq[['Mkt-RF']])).fit()\n",
    "print(model1.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                            OLS Regression Results                            \n",
      "==============================================================================\n",
      "Dep. Variable:                   10-1   R-squared:                       0.131\n",
      "Model:                            OLS   Adj. R-squared:                  0.130\n",
      "Method:                 Least Squares   F-statistic:                     169.0\n",
      "Date:                Sun, 21 Apr 2024   Prob (F-statistic):           4.16e-36\n",
      "Time:                        22:26:34   Log-Likelihood:                -3932.9\n",
      "No. Observations:                1128   AIC:                             7870.\n",
      "Df Residuals:                    1126   BIC:                             7880.\n",
      "Df Model:                           1                                         \n",
      "Covariance Type:            nonrobust                                         \n",
      "==============================================================================\n",
      "                 coef    std err          t      P>|t|      [0.025      0.975]\n",
      "------------------------------------------------------------------------------\n",
      "const          1.6393      0.237      6.903      0.000       1.173       2.105\n",
      "Mkt-RF        -0.5711      0.044    -13.001      0.000      -0.657      -0.485\n",
      "==============================================================================\n",
      "Omnibus:                      303.158   Durbin-Watson:                   2.002\n",
      "Prob(Omnibus):                  0.000   Jarque-Bera (JB):             2228.775\n",
      "Skew:                          -1.034   Prob(JB):                         0.00\n",
      "Kurtosis:                       9.568   Cond. No.                         5.45\n",
      "==============================================================================\n",
      "\n",
      "Notes:\n",
      "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n"
     ]
    }
   ],
   "source": [
    "# Estimate CAPM - value weighted\n",
    "model1=sm.OLS(ff3_merged_val['10-1'],\n",
    "              sm.add_constant(ff3_merged_val[['Mkt-RF']])).fit()\n",
    "print(model1.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                            OLS Regression Results                            \n",
      "==============================================================================\n",
      "Dep. Variable:                   10-1   R-squared:                       0.233\n",
      "Model:                            OLS   Adj. R-squared:                  0.231\n",
      "Method:                 Least Squares   F-statistic:                     113.6\n",
      "Date:                Sun, 21 Apr 2024   Prob (F-statistic):           2.93e-64\n",
      "Time:                        22:26:46   Log-Likelihood:                -3806.9\n",
      "No. Observations:                1128   AIC:                             7622.\n",
      "Df Residuals:                    1124   BIC:                             7642.\n",
      "Df Model:                           3                                         \n",
      "Covariance Type:            nonrobust                                         \n",
      "==============================================================================\n",
      "                 coef    std err          t      P>|t|      [0.025      0.975]\n",
      "------------------------------------------------------------------------------\n",
      "const          1.0890      0.213      5.111      0.000       0.671       1.507\n",
      "Mkt-RF        -0.1837      0.043     -4.318      0.000      -0.267      -0.100\n",
      "SMB           -0.5875      0.070     -8.385      0.000      -0.725      -0.450\n",
      "HML           -0.7501      0.062    -12.143      0.000      -0.871      -0.629\n",
      "==============================================================================\n",
      "Omnibus:                      532.666   Durbin-Watson:                   2.036\n",
      "Prob(Omnibus):                  0.000   Jarque-Bera (JB):            10488.898\n",
      "Skew:                          -1.695   Prob(JB):                         0.00\n",
      "Kurtosis:                      17.549   Cond. No.                         5.72\n",
      "==============================================================================\n",
      "\n",
      "Notes:\n",
      "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n"
     ]
    }
   ],
   "source": [
    "# Estimate FF3 - equally weighted\n",
    "model1=sm.OLS(ff3_merged_eq['10-1'],\n",
    "              sm.add_constant(ff3_merged_eq[['Mkt-RF', 'SMB', 'HML']])).fit()\n",
    "print(model1.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                            OLS Regression Results                            \n",
      "==============================================================================\n",
      "Dep. Variable:                   10-1   R-squared:                       0.238\n",
      "Model:                            OLS   Adj. R-squared:                  0.236\n",
      "Method:                 Least Squares   F-statistic:                     117.1\n",
      "Date:                Sun, 21 Apr 2024   Prob (F-statistic):           5.41e-66\n",
      "Time:                        22:26:59   Log-Likelihood:                -3858.3\n",
      "No. Observations:                1128   AIC:                             7725.\n",
      "Df Residuals:                    1124   BIC:                             7745.\n",
      "Df Model:                           3                                         \n",
      "Covariance Type:            nonrobust                                         \n",
      "==============================================================================\n",
      "                 coef    std err          t      P>|t|      [0.025      0.975]\n",
      "------------------------------------------------------------------------------\n",
      "const          1.8253      0.223      8.186      0.000       1.388       2.263\n",
      "Mkt-RF        -0.3951      0.045     -8.876      0.000      -0.482      -0.308\n",
      "SMB           -0.2814      0.073     -3.838      0.000      -0.425      -0.138\n",
      "HML           -0.7620      0.065    -11.787      0.000      -0.889      -0.635\n",
      "==============================================================================\n",
      "Omnibus:                      182.105   Durbin-Watson:                   2.042\n",
      "Prob(Omnibus):                  0.000   Jarque-Bera (JB):              885.929\n",
      "Skew:                          -0.658   Prob(JB):                    4.20e-193\n",
      "Kurtosis:                       7.137   Cond. No.                         5.72\n",
      "==============================================================================\n",
      "\n",
      "Notes:\n",
      "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n"
     ]
    }
   ],
   "source": [
    "# Estimate FF3 - value weighted\n",
    "model1=sm.OLS(ff3_merged_val['10-1'],\n",
    "              sm.add_constant(ff3_merged_val[['Mkt-RF', 'SMB', 'HML']])).fit()\n",
    "print(model1.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                            OLS Regression Results                            \n",
      "==============================================================================\n",
      "Dep. Variable:                   10-1   R-squared:                       0.083\n",
      "Model:                            OLS   Adj. R-squared:                  0.076\n",
      "Method:                 Least Squares   F-statistic:                     12.33\n",
      "Date:                Sun, 21 Apr 2024   Prob (F-statistic):           1.81e-11\n",
      "Time:                        22:27:04   Log-Likelihood:                -2281.9\n",
      "No. Observations:                 690   AIC:                             4576.\n",
      "Df Residuals:                     684   BIC:                             4603.\n",
      "Df Model:                           5                                         \n",
      "Covariance Type:            nonrobust                                         \n",
      "==============================================================================\n",
      "                 coef    std err          t      P>|t|      [0.025      0.975]\n",
      "------------------------------------------------------------------------------\n",
      "const          0.5677      0.264      2.149      0.032       0.049       1.087\n",
      "Mkt-RF        -0.1076      0.064     -1.669      0.096      -0.234       0.019\n",
      "SMB           -0.2323      0.092     -2.529      0.012      -0.413      -0.052\n",
      "HML           -0.5545      0.122     -4.546      0.000      -0.794      -0.315\n",
      "RMW            0.4955      0.128      3.875      0.000       0.244       0.747\n",
      "CMA            0.4075      0.188      2.164      0.031       0.038       0.777\n",
      "==============================================================================\n",
      "Omnibus:                      334.823   Durbin-Watson:                   2.108\n",
      "Prob(Omnibus):                  0.000   Jarque-Bera (JB):             5641.162\n",
      "Skew:                          -1.744   Prob(JB):                         0.00\n",
      "Kurtosis:                      16.567   Cond. No.                         5.19\n",
      "==============================================================================\n",
      "\n",
      "Notes:\n",
      "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n"
     ]
    }
   ],
   "source": [
    "# Estimate FF5 - equally weighted\n",
    "model1=sm.OLS(ff5_merged_eq['10-1'],\n",
    "              sm.add_constant(ff5_merged_eq[['Mkt-RF', 'SMB', 'HML', 'RMW', 'CMA']])).fit()\n",
    "print(model1.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                            OLS Regression Results                            \n",
      "==============================================================================\n",
      "Dep. Variable:                   10-1   R-squared:                       0.105\n",
      "Model:                            OLS   Adj. R-squared:                  0.098\n",
      "Method:                 Least Squares   F-statistic:                     16.00\n",
      "Date:                Sun, 21 Apr 2024   Prob (F-statistic):           6.32e-15\n",
      "Time:                        22:27:16   Log-Likelihood:                -2374.8\n",
      "No. Observations:                 690   AIC:                             4762.\n",
      "Df Residuals:                     684   BIC:                             4789.\n",
      "Df Model:                           5                                         \n",
      "Covariance Type:            nonrobust                                         \n",
      "==============================================================================\n",
      "                 coef    std err          t      P>|t|      [0.025      0.975]\n",
      "------------------------------------------------------------------------------\n",
      "const          1.6945      0.302      5.606      0.000       1.101       2.288\n",
      "Mkt-RF        -0.3285      0.074     -4.454      0.000      -0.473      -0.184\n",
      "SMB           -0.1043      0.105     -0.992      0.321      -0.311       0.102\n",
      "HML           -0.7944      0.140     -5.693      0.000      -1.068      -0.520\n",
      "RMW            0.4560      0.146      3.117      0.002       0.169       0.743\n",
      "CMA            0.4986      0.215      2.315      0.021       0.076       0.921\n",
      "==============================================================================\n",
      "Omnibus:                      116.733   Durbin-Watson:                   2.057\n",
      "Prob(Omnibus):                  0.000   Jarque-Bera (JB):              584.455\n",
      "Skew:                          -0.656   Prob(JB):                    1.22e-127\n",
      "Kurtosis:                       7.314   Cond. No.                         5.19\n",
      "==============================================================================\n",
      "\n",
      "Notes:\n",
      "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n"
     ]
    }
   ],
   "source": [
    "# Estimate FF5 - value weighted\n",
    "model1=sm.OLS(ff5_merged_val['10-1'],\n",
    "              sm.add_constant(ff5_merged_val[['Mkt-RF', 'SMB', 'HML', 'RMW', 'CMA']])).fit()\n",
    "print(model1.summary())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Comparing the CAPM, FF3, and FF5 equal-weighted alphas to the value-weighted alphas, we can see that the value-weighted portfolio performs much better, potentially implying that larger firms experience the effects of momentum more noticeably. We also notice that the CAPM, FF3, and FF5 models generally generate alphas that are statistically significant at the 5% level. Additionally, we can see that under the FF5 model, the alphas for both the equal-weighted and value-weighted drop slightly, suggesting that the FF5 model does price momentum to some degree."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Part e"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The high momentum alphas are not necessarily indicative of managerial skill. High alphas can also be a result of taking on additional risk that is not accounted for in the model. For example, the momentum strategy is known to have crash risk, and it tends to perform poorly in extreme down markets. If the model does not account for this risk, it can show up as positive alpha. Thus, while a positive alpha could be indicative of managerial skill, it could also be a sign of additional unaccounted risks or model misspecification."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Question 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\danie\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\statsmodels\\regression\\rolling.py:255: RuntimeWarning: divide by zero encountered in double_scalars\n",
      "  s2 = ssr / (nobs - tot_params)\n",
      "c:\\Users\\danie\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\statsmodels\\regression\\rolling.py:255: RuntimeWarning: divide by zero encountered in double_scalars\n",
      "  s2 = ssr / (nobs - tot_params)\n",
      "c:\\Users\\danie\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\statsmodels\\regression\\rolling.py:255: RuntimeWarning: divide by zero encountered in double_scalars\n",
      "  s2 = ssr / (nobs - tot_params)\n",
      "c:\\Users\\danie\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\statsmodels\\regression\\rolling.py:255: RuntimeWarning: divide by zero encountered in double_scalars\n",
      "  s2 = ssr / (nobs - tot_params)\n",
      "c:\\Users\\danie\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\statsmodels\\regression\\rolling.py:255: RuntimeWarning: divide by zero encountered in double_scalars\n",
      "  s2 = ssr / (nobs - tot_params)\n",
      "c:\\Users\\danie\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\statsmodels\\regression\\rolling.py:255: RuntimeWarning: divide by zero encountered in double_scalars\n",
      "  s2 = ssr / (nobs - tot_params)\n",
      "c:\\Users\\danie\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\statsmodels\\regression\\rolling.py:255: RuntimeWarning: divide by zero encountered in double_scalars\n",
      "  s2 = ssr / (nobs - tot_params)\n",
      "c:\\Users\\danie\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\statsmodels\\regression\\rolling.py:255: RuntimeWarning: divide by zero encountered in double_scalars\n",
      "  s2 = ssr / (nobs - tot_params)\n",
      "c:\\Users\\danie\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\statsmodels\\regression\\rolling.py:255: RuntimeWarning: divide by zero encountered in double_scalars\n",
      "  s2 = ssr / (nobs - tot_params)\n",
      "c:\\Users\\danie\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\statsmodels\\regression\\rolling.py:255: RuntimeWarning: divide by zero encountered in double_scalars\n",
      "  s2 = ssr / (nobs - tot_params)\n",
      "c:\\Users\\danie\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\statsmodels\\regression\\rolling.py:255: RuntimeWarning: divide by zero encountered in double_scalars\n",
      "  s2 = ssr / (nobs - tot_params)\n",
      "c:\\Users\\danie\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\statsmodels\\regression\\rolling.py:255: RuntimeWarning: divide by zero encountered in double_scalars\n",
      "  s2 = ssr / (nobs - tot_params)\n",
      "c:\\Users\\danie\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\statsmodels\\regression\\rolling.py:255: RuntimeWarning: divide by zero encountered in double_scalars\n",
      "  s2 = ssr / (nobs - tot_params)\n",
      "c:\\Users\\danie\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\statsmodels\\regression\\rolling.py:255: RuntimeWarning: divide by zero encountered in double_scalars\n",
      "  s2 = ssr / (nobs - tot_params)\n",
      "c:\\Users\\danie\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\statsmodels\\regression\\rolling.py:255: RuntimeWarning: divide by zero encountered in double_scalars\n",
      "  s2 = ssr / (nobs - tot_params)\n",
      "c:\\Users\\danie\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\statsmodels\\regression\\rolling.py:255: RuntimeWarning: divide by zero encountered in double_scalars\n",
      "  s2 = ssr / (nobs - tot_params)\n",
      "c:\\Users\\danie\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\statsmodels\\regression\\rolling.py:255: RuntimeWarning: divide by zero encountered in double_scalars\n",
      "  s2 = ssr / (nobs - tot_params)\n",
      "c:\\Users\\danie\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\statsmodels\\regression\\rolling.py:255: RuntimeWarning: divide by zero encountered in double_scalars\n",
      "  s2 = ssr / (nobs - tot_params)\n",
      "c:\\Users\\danie\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\statsmodels\\regression\\rolling.py:255: RuntimeWarning: divide by zero encountered in double_scalars\n",
      "  s2 = ssr / (nobs - tot_params)\n",
      "c:\\Users\\danie\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\statsmodels\\regression\\rolling.py:255: RuntimeWarning: divide by zero encountered in double_scalars\n",
      "  s2 = ssr / (nobs - tot_params)\n",
      "c:\\Users\\danie\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\statsmodels\\regression\\rolling.py:255: RuntimeWarning: divide by zero encountered in double_scalars\n",
      "  s2 = ssr / (nobs - tot_params)\n",
      "c:\\Users\\danie\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\statsmodels\\regression\\rolling.py:255: RuntimeWarning: divide by zero encountered in double_scalars\n",
      "  s2 = ssr / (nobs - tot_params)\n",
      "c:\\Users\\danie\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\statsmodels\\regression\\rolling.py:255: RuntimeWarning: divide by zero encountered in double_scalars\n",
      "  s2 = ssr / (nobs - tot_params)\n",
      "c:\\Users\\danie\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\statsmodels\\regression\\rolling.py:255: RuntimeWarning: divide by zero encountered in double_scalars\n",
      "  s2 = ssr / (nobs - tot_params)\n",
      "c:\\Users\\danie\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\statsmodels\\regression\\rolling.py:255: RuntimeWarning: divide by zero encountered in double_scalars\n",
      "  s2 = ssr / (nobs - tot_params)\n",
      "c:\\Users\\danie\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\statsmodels\\regression\\rolling.py:255: RuntimeWarning: divide by zero encountered in double_scalars\n",
      "  s2 = ssr / (nobs - tot_params)\n",
      "c:\\Users\\danie\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\statsmodels\\regression\\rolling.py:255: RuntimeWarning: divide by zero encountered in double_scalars\n",
      "  s2 = ssr / (nobs - tot_params)\n",
      "c:\\Users\\danie\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\statsmodels\\regression\\rolling.py:255: RuntimeWarning: divide by zero encountered in double_scalars\n",
      "  s2 = ssr / (nobs - tot_params)\n",
      "c:\\Users\\danie\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\statsmodels\\regression\\rolling.py:255: RuntimeWarning: divide by zero encountered in double_scalars\n",
      "  s2 = ssr / (nobs - tot_params)\n",
      "c:\\Users\\danie\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\statsmodels\\regression\\rolling.py:255: RuntimeWarning: divide by zero encountered in double_scalars\n",
      "  s2 = ssr / (nobs - tot_params)\n",
      "c:\\Users\\danie\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\statsmodels\\regression\\rolling.py:255: RuntimeWarning: divide by zero encountered in double_scalars\n",
      "  s2 = ssr / (nobs - tot_params)\n",
      "c:\\Users\\danie\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\statsmodels\\regression\\rolling.py:255: RuntimeWarning: divide by zero encountered in double_scalars\n",
      "  s2 = ssr / (nobs - tot_params)\n",
      "c:\\Users\\danie\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\statsmodels\\regression\\rolling.py:255: RuntimeWarning: divide by zero encountered in double_scalars\n",
      "  s2 = ssr / (nobs - tot_params)\n",
      "c:\\Users\\danie\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\statsmodels\\regression\\rolling.py:255: RuntimeWarning: divide by zero encountered in double_scalars\n",
      "  s2 = ssr / (nobs - tot_params)\n",
      "c:\\Users\\danie\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\statsmodels\\regression\\rolling.py:255: RuntimeWarning: divide by zero encountered in double_scalars\n",
      "  s2 = ssr / (nobs - tot_params)\n",
      "c:\\Users\\danie\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\statsmodels\\regression\\rolling.py:255: RuntimeWarning: divide by zero encountered in double_scalars\n",
      "  s2 = ssr / (nobs - tot_params)\n",
      "c:\\Users\\danie\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\statsmodels\\regression\\rolling.py:255: RuntimeWarning: divide by zero encountered in double_scalars\n",
      "  s2 = ssr / (nobs - tot_params)\n",
      "c:\\Users\\danie\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\statsmodels\\regression\\rolling.py:255: RuntimeWarning: divide by zero encountered in double_scalars\n",
      "  s2 = ssr / (nobs - tot_params)\n",
      "c:\\Users\\danie\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\statsmodels\\regression\\rolling.py:255: RuntimeWarning: divide by zero encountered in double_scalars\n",
      "  s2 = ssr / (nobs - tot_params)\n",
      "c:\\Users\\danie\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\statsmodels\\regression\\rolling.py:255: RuntimeWarning: divide by zero encountered in double_scalars\n",
      "  s2 = ssr / (nobs - tot_params)\n",
      "c:\\Users\\danie\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\statsmodels\\regression\\rolling.py:255: RuntimeWarning: divide by zero encountered in double_scalars\n",
      "  s2 = ssr / (nobs - tot_params)\n",
      "c:\\Users\\danie\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\statsmodels\\regression\\rolling.py:255: RuntimeWarning: divide by zero encountered in double_scalars\n",
      "  s2 = ssr / (nobs - tot_params)\n",
      "c:\\Users\\danie\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\statsmodels\\regression\\rolling.py:255: RuntimeWarning: divide by zero encountered in double_scalars\n",
      "  s2 = ssr / (nobs - tot_params)\n",
      "c:\\Users\\danie\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\statsmodels\\regression\\rolling.py:255: RuntimeWarning: divide by zero encountered in double_scalars\n",
      "  s2 = ssr / (nobs - tot_params)\n",
      "c:\\Users\\danie\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\statsmodels\\regression\\rolling.py:255: RuntimeWarning: divide by zero encountered in double_scalars\n",
      "  s2 = ssr / (nobs - tot_params)\n",
      "c:\\Users\\danie\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\statsmodels\\regression\\rolling.py:255: RuntimeWarning: divide by zero encountered in double_scalars\n",
      "  s2 = ssr / (nobs - tot_params)\n",
      "c:\\Users\\danie\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\statsmodels\\regression\\rolling.py:255: RuntimeWarning: divide by zero encountered in double_scalars\n",
      "  s2 = ssr / (nobs - tot_params)\n",
      "c:\\Users\\danie\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\statsmodels\\regression\\rolling.py:255: RuntimeWarning: divide by zero encountered in double_scalars\n",
      "  s2 = ssr / (nobs - tot_params)\n",
      "c:\\Users\\danie\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\statsmodels\\regression\\rolling.py:255: RuntimeWarning: divide by zero encountered in double_scalars\n",
      "  s2 = ssr / (nobs - tot_params)\n",
      "c:\\Users\\danie\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\statsmodels\\regression\\rolling.py:255: RuntimeWarning: divide by zero encountered in double_scalars\n",
      "  s2 = ssr / (nobs - tot_params)\n",
      "c:\\Users\\danie\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\statsmodels\\regression\\rolling.py:255: RuntimeWarning: divide by zero encountered in double_scalars\n",
      "  s2 = ssr / (nobs - tot_params)\n",
      "c:\\Users\\danie\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\statsmodels\\regression\\rolling.py:255: RuntimeWarning: divide by zero encountered in double_scalars\n",
      "  s2 = ssr / (nobs - tot_params)\n",
      "c:\\Users\\danie\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\statsmodels\\regression\\rolling.py:255: RuntimeWarning: divide by zero encountered in double_scalars\n",
      "  s2 = ssr / (nobs - tot_params)\n",
      "c:\\Users\\danie\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\statsmodels\\regression\\rolling.py:255: RuntimeWarning: divide by zero encountered in double_scalars\n",
      "  s2 = ssr / (nobs - tot_params)\n",
      "c:\\Users\\danie\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\statsmodels\\regression\\rolling.py:255: RuntimeWarning: divide by zero encountered in double_scalars\n",
      "  s2 = ssr / (nobs - tot_params)\n",
      "c:\\Users\\danie\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\statsmodels\\regression\\rolling.py:255: RuntimeWarning: divide by zero encountered in double_scalars\n",
      "  s2 = ssr / (nobs - tot_params)\n",
      "c:\\Users\\danie\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\statsmodels\\regression\\rolling.py:255: RuntimeWarning: divide by zero encountered in double_scalars\n",
      "  s2 = ssr / (nobs - tot_params)\n",
      "c:\\Users\\danie\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\statsmodels\\regression\\rolling.py:255: RuntimeWarning: divide by zero encountered in double_scalars\n",
      "  s2 = ssr / (nobs - tot_params)\n",
      "c:\\Users\\danie\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\statsmodels\\regression\\rolling.py:255: RuntimeWarning: divide by zero encountered in double_scalars\n",
      "  s2 = ssr / (nobs - tot_params)\n",
      "c:\\Users\\danie\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\statsmodels\\regression\\rolling.py:255: RuntimeWarning: divide by zero encountered in double_scalars\n",
      "  s2 = ssr / (nobs - tot_params)\n",
      "c:\\Users\\danie\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\statsmodels\\regression\\rolling.py:255: RuntimeWarning: divide by zero encountered in double_scalars\n",
      "  s2 = ssr / (nobs - tot_params)\n",
      "c:\\Users\\danie\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\statsmodels\\regression\\rolling.py:255: RuntimeWarning: divide by zero encountered in double_scalars\n",
      "  s2 = ssr / (nobs - tot_params)\n",
      "c:\\Users\\danie\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\statsmodels\\regression\\rolling.py:255: RuntimeWarning: divide by zero encountered in double_scalars\n",
      "  s2 = ssr / (nobs - tot_params)\n",
      "c:\\Users\\danie\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\statsmodels\\regression\\rolling.py:255: RuntimeWarning: divide by zero encountered in double_scalars\n",
      "  s2 = ssr / (nobs - tot_params)\n",
      "c:\\Users\\danie\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\statsmodels\\regression\\rolling.py:255: RuntimeWarning: divide by zero encountered in double_scalars\n",
      "  s2 = ssr / (nobs - tot_params)\n",
      "c:\\Users\\danie\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\statsmodels\\regression\\rolling.py:255: RuntimeWarning: divide by zero encountered in double_scalars\n",
      "  s2 = ssr / (nobs - tot_params)\n",
      "c:\\Users\\danie\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\statsmodels\\regression\\rolling.py:255: RuntimeWarning: divide by zero encountered in double_scalars\n",
      "  s2 = ssr / (nobs - tot_params)\n",
      "c:\\Users\\danie\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\statsmodels\\regression\\rolling.py:255: RuntimeWarning: divide by zero encountered in double_scalars\n",
      "  s2 = ssr / (nobs - tot_params)\n",
      "c:\\Users\\danie\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\statsmodels\\regression\\rolling.py:255: RuntimeWarning: divide by zero encountered in double_scalars\n",
      "  s2 = ssr / (nobs - tot_params)\n",
      "c:\\Users\\danie\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\statsmodels\\regression\\rolling.py:255: RuntimeWarning: divide by zero encountered in double_scalars\n",
      "  s2 = ssr / (nobs - tot_params)\n",
      "c:\\Users\\danie\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\statsmodels\\regression\\rolling.py:255: RuntimeWarning: divide by zero encountered in double_scalars\n",
      "  s2 = ssr / (nobs - tot_params)\n",
      "c:\\Users\\danie\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\statsmodels\\regression\\rolling.py:255: RuntimeWarning: divide by zero encountered in double_scalars\n",
      "  s2 = ssr / (nobs - tot_params)\n",
      "c:\\Users\\danie\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\statsmodels\\regression\\rolling.py:255: RuntimeWarning: divide by zero encountered in double_scalars\n",
      "  s2 = ssr / (nobs - tot_params)\n",
      "c:\\Users\\danie\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\statsmodels\\regression\\rolling.py:255: RuntimeWarning: divide by zero encountered in double_scalars\n",
      "  s2 = ssr / (nobs - tot_params)\n",
      "c:\\Users\\danie\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\statsmodels\\regression\\rolling.py:255: RuntimeWarning: divide by zero encountered in double_scalars\n",
      "  s2 = ssr / (nobs - tot_params)\n",
      "c:\\Users\\danie\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\statsmodels\\regression\\rolling.py:255: RuntimeWarning: divide by zero encountered in double_scalars\n",
      "  s2 = ssr / (nobs - tot_params)\n",
      "c:\\Users\\danie\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\statsmodels\\regression\\rolling.py:255: RuntimeWarning: divide by zero encountered in double_scalars\n",
      "  s2 = ssr / (nobs - tot_params)\n",
      "c:\\Users\\danie\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\statsmodels\\regression\\rolling.py:255: RuntimeWarning: divide by zero encountered in double_scalars\n",
      "  s2 = ssr / (nobs - tot_params)\n",
      "c:\\Users\\danie\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\statsmodels\\regression\\rolling.py:255: RuntimeWarning: divide by zero encountered in double_scalars\n",
      "  s2 = ssr / (nobs - tot_params)\n",
      "c:\\Users\\danie\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\statsmodels\\regression\\rolling.py:255: RuntimeWarning: divide by zero encountered in double_scalars\n",
      "  s2 = ssr / (nobs - tot_params)\n",
      "c:\\Users\\danie\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\statsmodels\\regression\\rolling.py:255: RuntimeWarning: divide by zero encountered in double_scalars\n",
      "  s2 = ssr / (nobs - tot_params)\n",
      "c:\\Users\\danie\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\statsmodels\\regression\\rolling.py:255: RuntimeWarning: divide by zero encountered in double_scalars\n",
      "  s2 = ssr / (nobs - tot_params)\n",
      "c:\\Users\\danie\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\statsmodels\\regression\\rolling.py:255: RuntimeWarning: divide by zero encountered in double_scalars\n",
      "  s2 = ssr / (nobs - tot_params)\n",
      "c:\\Users\\danie\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\statsmodels\\regression\\rolling.py:255: RuntimeWarning: divide by zero encountered in double_scalars\n",
      "  s2 = ssr / (nobs - tot_params)\n",
      "c:\\Users\\danie\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\statsmodels\\regression\\rolling.py:255: RuntimeWarning: divide by zero encountered in double_scalars\n",
      "  s2 = ssr / (nobs - tot_params)\n",
      "c:\\Users\\danie\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\statsmodels\\regression\\rolling.py:255: RuntimeWarning: divide by zero encountered in double_scalars\n",
      "  s2 = ssr / (nobs - tot_params)\n",
      "c:\\Users\\danie\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\statsmodels\\regression\\rolling.py:255: RuntimeWarning: divide by zero encountered in double_scalars\n",
      "  s2 = ssr / (nobs - tot_params)\n",
      "c:\\Users\\danie\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\statsmodels\\regression\\rolling.py:255: RuntimeWarning: divide by zero encountered in double_scalars\n",
      "  s2 = ssr / (nobs - tot_params)\n",
      "c:\\Users\\danie\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\statsmodels\\regression\\rolling.py:255: RuntimeWarning: divide by zero encountered in double_scalars\n",
      "  s2 = ssr / (nobs - tot_params)\n",
      "c:\\Users\\danie\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\statsmodels\\regression\\rolling.py:255: RuntimeWarning: divide by zero encountered in double_scalars\n",
      "  s2 = ssr / (nobs - tot_params)\n",
      "c:\\Users\\danie\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\statsmodels\\regression\\rolling.py:255: RuntimeWarning: divide by zero encountered in double_scalars\n",
      "  s2 = ssr / (nobs - tot_params)\n",
      "c:\\Users\\danie\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\statsmodels\\regression\\rolling.py:255: RuntimeWarning: divide by zero encountered in double_scalars\n",
      "  s2 = ssr / (nobs - tot_params)\n",
      "c:\\Users\\danie\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\statsmodels\\regression\\rolling.py:255: RuntimeWarning: divide by zero encountered in double_scalars\n",
      "  s2 = ssr / (nobs - tot_params)\n",
      "c:\\Users\\danie\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\statsmodels\\regression\\rolling.py:255: RuntimeWarning: divide by zero encountered in double_scalars\n",
      "  s2 = ssr / (nobs - tot_params)\n",
      "c:\\Users\\danie\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\statsmodels\\regression\\rolling.py:255: RuntimeWarning: divide by zero encountered in double_scalars\n",
      "  s2 = ssr / (nobs - tot_params)\n",
      "c:\\Users\\danie\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\statsmodels\\regression\\rolling.py:255: RuntimeWarning: divide by zero encountered in double_scalars\n",
      "  s2 = ssr / (nobs - tot_params)\n",
      "c:\\Users\\danie\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\statsmodels\\regression\\rolling.py:255: RuntimeWarning: divide by zero encountered in double_scalars\n",
      "  s2 = ssr / (nobs - tot_params)\n",
      "c:\\Users\\danie\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\statsmodels\\regression\\rolling.py:255: RuntimeWarning: divide by zero encountered in double_scalars\n",
      "  s2 = ssr / (nobs - tot_params)\n",
      "c:\\Users\\danie\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\statsmodels\\regression\\rolling.py:255: RuntimeWarning: divide by zero encountered in double_scalars\n",
      "  s2 = ssr / (nobs - tot_params)\n",
      "c:\\Users\\danie\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\statsmodels\\regression\\rolling.py:255: RuntimeWarning: divide by zero encountered in double_scalars\n",
      "  s2 = ssr / (nobs - tot_params)\n",
      "c:\\Users\\danie\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\statsmodels\\regression\\rolling.py:255: RuntimeWarning: divide by zero encountered in double_scalars\n",
      "  s2 = ssr / (nobs - tot_params)\n",
      "c:\\Users\\danie\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\statsmodels\\regression\\rolling.py:255: RuntimeWarning: divide by zero encountered in double_scalars\n",
      "  s2 = ssr / (nobs - tot_params)\n",
      "c:\\Users\\danie\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\statsmodels\\regression\\rolling.py:255: RuntimeWarning: divide by zero encountered in double_scalars\n",
      "  s2 = ssr / (nobs - tot_params)\n",
      "c:\\Users\\danie\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\statsmodels\\regression\\rolling.py:255: RuntimeWarning: divide by zero encountered in double_scalars\n",
      "  s2 = ssr / (nobs - tot_params)\n",
      "c:\\Users\\danie\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\statsmodels\\regression\\rolling.py:255: RuntimeWarning: divide by zero encountered in double_scalars\n",
      "  s2 = ssr / (nobs - tot_params)\n",
      "c:\\Users\\danie\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\statsmodels\\regression\\rolling.py:255: RuntimeWarning: divide by zero encountered in double_scalars\n",
      "  s2 = ssr / (nobs - tot_params)\n",
      "c:\\Users\\danie\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\statsmodels\\regression\\rolling.py:255: RuntimeWarning: divide by zero encountered in double_scalars\n",
      "  s2 = ssr / (nobs - tot_params)\n",
      "c:\\Users\\danie\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\statsmodels\\regression\\rolling.py:255: RuntimeWarning: divide by zero encountered in double_scalars\n",
      "  s2 = ssr / (nobs - tot_params)\n",
      "c:\\Users\\danie\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\statsmodels\\regression\\rolling.py:255: RuntimeWarning: divide by zero encountered in double_scalars\n",
      "  s2 = ssr / (nobs - tot_params)\n",
      "c:\\Users\\danie\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\statsmodels\\regression\\rolling.py:255: RuntimeWarning: divide by zero encountered in double_scalars\n",
      "  s2 = ssr / (nobs - tot_params)\n",
      "c:\\Users\\danie\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\statsmodels\\regression\\rolling.py:255: RuntimeWarning: divide by zero encountered in double_scalars\n",
      "  s2 = ssr / (nobs - tot_params)\n",
      "c:\\Users\\danie\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\statsmodels\\regression\\rolling.py:255: RuntimeWarning: divide by zero encountered in double_scalars\n",
      "  s2 = ssr / (nobs - tot_params)\n",
      "c:\\Users\\danie\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\statsmodels\\regression\\rolling.py:255: RuntimeWarning: divide by zero encountered in double_scalars\n",
      "  s2 = ssr / (nobs - tot_params)\n",
      "c:\\Users\\danie\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\statsmodels\\regression\\rolling.py:255: RuntimeWarning: divide by zero encountered in double_scalars\n",
      "  s2 = ssr / (nobs - tot_params)\n",
      "c:\\Users\\danie\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\statsmodels\\regression\\rolling.py:255: RuntimeWarning: divide by zero encountered in double_scalars\n",
      "  s2 = ssr / (nobs - tot_params)\n",
      "c:\\Users\\danie\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\statsmodels\\regression\\rolling.py:255: RuntimeWarning: divide by zero encountered in double_scalars\n",
      "  s2 = ssr / (nobs - tot_params)\n",
      "c:\\Users\\danie\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\statsmodels\\regression\\rolling.py:255: RuntimeWarning: divide by zero encountered in double_scalars\n",
      "  s2 = ssr / (nobs - tot_params)\n",
      "c:\\Users\\danie\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\statsmodels\\regression\\rolling.py:255: RuntimeWarning: divide by zero encountered in double_scalars\n",
      "  s2 = ssr / (nobs - tot_params)\n",
      "c:\\Users\\danie\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\statsmodels\\regression\\rolling.py:255: RuntimeWarning: divide by zero encountered in double_scalars\n",
      "  s2 = ssr / (nobs - tot_params)\n",
      "c:\\Users\\danie\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\statsmodels\\regression\\rolling.py:255: RuntimeWarning: divide by zero encountered in double_scalars\n",
      "  s2 = ssr / (nobs - tot_params)\n",
      "c:\\Users\\danie\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\statsmodels\\regression\\rolling.py:255: RuntimeWarning: divide by zero encountered in double_scalars\n",
      "  s2 = ssr / (nobs - tot_params)\n",
      "c:\\Users\\danie\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\statsmodels\\regression\\rolling.py:255: RuntimeWarning: divide by zero encountered in double_scalars\n",
      "  s2 = ssr / (nobs - tot_params)\n",
      "c:\\Users\\danie\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\statsmodels\\regression\\rolling.py:255: RuntimeWarning: divide by zero encountered in double_scalars\n",
      "  s2 = ssr / (nobs - tot_params)\n",
      "c:\\Users\\danie\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\statsmodels\\regression\\rolling.py:255: RuntimeWarning: divide by zero encountered in double_scalars\n",
      "  s2 = ssr / (nobs - tot_params)\n",
      "c:\\Users\\danie\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\statsmodels\\regression\\rolling.py:255: RuntimeWarning: divide by zero encountered in double_scalars\n",
      "  s2 = ssr / (nobs - tot_params)\n",
      "c:\\Users\\danie\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\statsmodels\\regression\\rolling.py:255: RuntimeWarning: divide by zero encountered in double_scalars\n",
      "  s2 = ssr / (nobs - tot_params)\n",
      "c:\\Users\\danie\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\statsmodels\\regression\\rolling.py:255: RuntimeWarning: divide by zero encountered in double_scalars\n",
      "  s2 = ssr / (nobs - tot_params)\n",
      "c:\\Users\\danie\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\statsmodels\\regression\\rolling.py:255: RuntimeWarning: divide by zero encountered in double_scalars\n",
      "  s2 = ssr / (nobs - tot_params)\n",
      "c:\\Users\\danie\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\statsmodels\\regression\\rolling.py:255: RuntimeWarning: divide by zero encountered in double_scalars\n",
      "  s2 = ssr / (nobs - tot_params)\n",
      "c:\\Users\\danie\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\statsmodels\\regression\\rolling.py:255: RuntimeWarning: divide by zero encountered in double_scalars\n",
      "  s2 = ssr / (nobs - tot_params)\n",
      "c:\\Users\\danie\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\statsmodels\\regression\\rolling.py:255: RuntimeWarning: divide by zero encountered in double_scalars\n",
      "  s2 = ssr / (nobs - tot_params)\n",
      "c:\\Users\\danie\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\statsmodels\\regression\\rolling.py:255: RuntimeWarning: divide by zero encountered in double_scalars\n",
      "  s2 = ssr / (nobs - tot_params)\n",
      "c:\\Users\\danie\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\statsmodels\\regression\\rolling.py:255: RuntimeWarning: divide by zero encountered in double_scalars\n",
      "  s2 = ssr / (nobs - tot_params)\n",
      "c:\\Users\\danie\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\statsmodels\\regression\\rolling.py:255: RuntimeWarning: divide by zero encountered in double_scalars\n",
      "  s2 = ssr / (nobs - tot_params)\n",
      "c:\\Users\\danie\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\statsmodels\\regression\\rolling.py:255: RuntimeWarning: divide by zero encountered in double_scalars\n",
      "  s2 = ssr / (nobs - tot_params)\n",
      "c:\\Users\\danie\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\statsmodels\\regression\\rolling.py:255: RuntimeWarning: divide by zero encountered in double_scalars\n",
      "  s2 = ssr / (nobs - tot_params)\n",
      "c:\\Users\\danie\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\statsmodels\\regression\\rolling.py:255: RuntimeWarning: divide by zero encountered in double_scalars\n",
      "  s2 = ssr / (nobs - tot_params)\n",
      "c:\\Users\\danie\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\statsmodels\\regression\\rolling.py:255: RuntimeWarning: divide by zero encountered in double_scalars\n",
      "  s2 = ssr / (nobs - tot_params)\n",
      "c:\\Users\\danie\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\statsmodels\\regression\\rolling.py:255: RuntimeWarning: divide by zero encountered in double_scalars\n",
      "  s2 = ssr / (nobs - tot_params)\n",
      "c:\\Users\\danie\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\statsmodels\\regression\\rolling.py:255: RuntimeWarning: divide by zero encountered in double_scalars\n",
      "  s2 = ssr / (nobs - tot_params)\n",
      "c:\\Users\\danie\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\statsmodels\\regression\\rolling.py:272: RuntimeWarning: divide by zero encountered in log\n",
      "  llf = -np.log(ssr) * nobs2  # concentrated likelihood\n",
      "c:\\Users\\danie\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\statsmodels\\regression\\rolling.py:255: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  s2 = ssr / (nobs - tot_params)\n",
      "c:\\Users\\danie\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\statsmodels\\regression\\rolling.py:255: RuntimeWarning: divide by zero encountered in double_scalars\n",
      "  s2 = ssr / (nobs - tot_params)\n",
      "c:\\Users\\danie\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\statsmodels\\regression\\rolling.py:255: RuntimeWarning: divide by zero encountered in double_scalars\n",
      "  s2 = ssr / (nobs - tot_params)\n",
      "c:\\Users\\danie\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\statsmodels\\regression\\rolling.py:255: RuntimeWarning: divide by zero encountered in double_scalars\n",
      "  s2 = ssr / (nobs - tot_params)\n",
      "c:\\Users\\danie\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\statsmodels\\regression\\rolling.py:255: RuntimeWarning: divide by zero encountered in double_scalars\n",
      "  s2 = ssr / (nobs - tot_params)\n",
      "c:\\Users\\danie\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\statsmodels\\regression\\rolling.py:255: RuntimeWarning: divide by zero encountered in double_scalars\n",
      "  s2 = ssr / (nobs - tot_params)\n",
      "c:\\Users\\danie\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\statsmodels\\regression\\rolling.py:255: RuntimeWarning: divide by zero encountered in double_scalars\n",
      "  s2 = ssr / (nobs - tot_params)\n",
      "c:\\Users\\danie\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\statsmodels\\regression\\rolling.py:255: RuntimeWarning: divide by zero encountered in double_scalars\n",
      "  s2 = ssr / (nobs - tot_params)\n",
      "c:\\Users\\danie\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\statsmodels\\regression\\rolling.py:255: RuntimeWarning: divide by zero encountered in double_scalars\n",
      "  s2 = ssr / (nobs - tot_params)\n"
     ]
    }
   ],
   "source": [
    "from statsmodels.regression.rolling import RollingOLS\n",
    "\n",
    "# Convert 'RET' column to numeric, turning non-numeric values into NaN\n",
    "crsp_data_cleaned['RET'] = pd.to_numeric(crsp_data_cleaned['RET'], errors='coerce')\n",
    "\n",
    "# Merge ff5 and crsp\n",
    "merged_df = pd.merge(crsp_data_cleaned, ff3, on='date', how='inner')\n",
    "\n",
    "# Define a function to calculate rolling betas\n",
    "def calc_rolling_beta(group):\n",
    "    if len(group) >= 36:\n",
    "        endog = group['RET']*100 - group['RF']\n",
    "        exog = sm.add_constant(group['Mkt-RF'])  # Add a constant to the exogenous variable\n",
    "        model = RollingOLS(endog, exog, window=36)\n",
    "        rolling_params = model.fit().params\n",
    "        group['rolling_beta'] = rolling_params['Mkt-RF'].values\n",
    "    else:\n",
    "        group['rolling_beta'] = np.nan\n",
    "    return group\n",
    "\n",
    "merged_df = merged_df.groupby('PERMNO').apply(calc_rolling_beta)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#merged_df.to_csv('merged_df.csv', index=False)\n",
    "\n",
    "# Now, to load the data back into a DataFrame\n",
    "merged_df = pd.read_csv('merged_df.csv')\n",
    "merged_df[\"rolling_beta\"] = merged_df.groupby('PERMNO')['rolling_beta'].shift(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop rows with NaN values in 'rolling_beta'\n",
    "merged_df = merged_df.dropna(subset=['rolling_beta'])\n",
    "\n",
    "# Make decile\n",
    "sortdf = merged_df.drop(['SHRCD', 'EXCHCD', 'PRC', 'SHROUT'], axis=1)\n",
    "sortdf['rank'] = sortdf.groupby('date')['rolling_beta'].rank(pct=True)\n",
    "sortdf['decile'] = np.ceil(sortdf['rank']*10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sortdf.reset_index(drop = True, inplace = True)\n",
    "\n",
    "# Form the equal- and value-weighted portfolios for the ten momentum portfolios\n",
    "def calc_weights(group):\n",
    "    group['weights_eq'] = 1 / float(group['decile'].count())\n",
    "    group['TME'] = group['ME'].sum()\n",
    "    group['weights_val'] = group['ME'] / group['TME']\n",
    "    return group\n",
    "\n",
    "sortdf = sortdf.groupby(['date', 'decile']).apply(calc_weights)\n",
    "\n",
    "sortdf['decile_lag'] = sortdf.groupby('PERMNO')['decile'].shift(1)\n",
    "sortdf['weights_val_lag'] = sortdf.groupby('PERMNO')['weights_val'].shift(1)\n",
    "sortdf['weights_eq_lag'] = sortdf.groupby('PERMNO')['weights_eq'].shift(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PERMNO</th>\n",
       "      <th>date</th>\n",
       "      <th>RET</th>\n",
       "      <th>date2</th>\n",
       "      <th>year_month</th>\n",
       "      <th>ME</th>\n",
       "      <th>cumulative_returns</th>\n",
       "      <th>Mkt-RF</th>\n",
       "      <th>SMB</th>\n",
       "      <th>HML</th>\n",
       "      <th>...</th>\n",
       "      <th>rank</th>\n",
       "      <th>decile</th>\n",
       "      <th>weights_eq</th>\n",
       "      <th>TME</th>\n",
       "      <th>weights_val</th>\n",
       "      <th>decile_lag</th>\n",
       "      <th>weights_val_lag</th>\n",
       "      <th>weights_eq_lag</th>\n",
       "      <th>weighted_val_lag</th>\n",
       "      <th>weighted_eq_lag</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>11404</td>\n",
       "      <td>192607</td>\n",
       "      <td>0.107323</td>\n",
       "      <td>1926-07-31</td>\n",
       "      <td>1926-07</td>\n",
       "      <td>39465.000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.96</td>\n",
       "      <td>-2.56</td>\n",
       "      <td>-2.43</td>\n",
       "      <td>...</td>\n",
       "      <td>0.044944</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.125000</td>\n",
       "      <td>8.615805e+04</td>\n",
       "      <td>0.458054</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>11674</td>\n",
       "      <td>192607</td>\n",
       "      <td>0.018657</td>\n",
       "      <td>1926-07-31</td>\n",
       "      <td>1926-07</td>\n",
       "      <td>10988.250</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.96</td>\n",
       "      <td>-2.56</td>\n",
       "      <td>-2.43</td>\n",
       "      <td>...</td>\n",
       "      <td>0.067416</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.125000</td>\n",
       "      <td>8.615805e+04</td>\n",
       "      <td>0.127536</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>12319</td>\n",
       "      <td>192607</td>\n",
       "      <td>0.019653</td>\n",
       "      <td>1926-07-31</td>\n",
       "      <td>1926-07</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.96</td>\n",
       "      <td>-2.56</td>\n",
       "      <td>-2.43</td>\n",
       "      <td>...</td>\n",
       "      <td>0.033708</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.125000</td>\n",
       "      <td>8.615805e+04</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>13688</td>\n",
       "      <td>192607</td>\n",
       "      <td>0.003906</td>\n",
       "      <td>1926-07-31</td>\n",
       "      <td>1926-07</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.96</td>\n",
       "      <td>-2.56</td>\n",
       "      <td>-2.43</td>\n",
       "      <td>...</td>\n",
       "      <td>0.078652</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.125000</td>\n",
       "      <td>8.615805e+04</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>14349</td>\n",
       "      <td>192607</td>\n",
       "      <td>0.025000</td>\n",
       "      <td>1926-07-31</td>\n",
       "      <td>1926-07</td>\n",
       "      <td>512.500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.96</td>\n",
       "      <td>-2.56</td>\n",
       "      <td>-2.43</td>\n",
       "      <td>...</td>\n",
       "      <td>0.022472</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.125000</td>\n",
       "      <td>8.615805e+04</td>\n",
       "      <td>0.005948</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2792214</th>\n",
       "      <td>93371</td>\n",
       "      <td>202012</td>\n",
       "      <td>-0.174444</td>\n",
       "      <td>2020-12-31</td>\n",
       "      <td>2020-12</td>\n",
       "      <td>23874.076</td>\n",
       "      <td>-0.176182</td>\n",
       "      <td>4.63</td>\n",
       "      <td>4.89</td>\n",
       "      <td>-1.50</td>\n",
       "      <td>...</td>\n",
       "      <td>0.930943</td>\n",
       "      <td>10.0</td>\n",
       "      <td>0.003311</td>\n",
       "      <td>5.315590e+07</td>\n",
       "      <td>0.000449</td>\n",
       "      <td>9.0</td>\n",
       "      <td>0.000207</td>\n",
       "      <td>0.003322</td>\n",
       "      <td>-0.000036</td>\n",
       "      <td>-0.000580</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2792215</th>\n",
       "      <td>93373</td>\n",
       "      <td>202012</td>\n",
       "      <td>-0.401316</td>\n",
       "      <td>2020-12-31</td>\n",
       "      <td>2020-12</td>\n",
       "      <td>5910.268</td>\n",
       "      <td>-0.844529</td>\n",
       "      <td>4.63</td>\n",
       "      <td>4.89</td>\n",
       "      <td>-1.50</td>\n",
       "      <td>...</td>\n",
       "      <td>0.974436</td>\n",
       "      <td>10.0</td>\n",
       "      <td>0.003311</td>\n",
       "      <td>5.315590e+07</td>\n",
       "      <td>0.000111</td>\n",
       "      <td>9.0</td>\n",
       "      <td>0.000070</td>\n",
       "      <td>0.003322</td>\n",
       "      <td>-0.000028</td>\n",
       "      <td>-0.001333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2792216</th>\n",
       "      <td>93393</td>\n",
       "      <td>202012</td>\n",
       "      <td>0.091997</td>\n",
       "      <td>2020-12-31</td>\n",
       "      <td>2020-12</td>\n",
       "      <td>105061.600</td>\n",
       "      <td>1.189962</td>\n",
       "      <td>4.63</td>\n",
       "      <td>4.89</td>\n",
       "      <td>-1.50</td>\n",
       "      <td>...</td>\n",
       "      <td>0.966799</td>\n",
       "      <td>10.0</td>\n",
       "      <td>0.003311</td>\n",
       "      <td>5.315590e+07</td>\n",
       "      <td>0.001976</td>\n",
       "      <td>10.0</td>\n",
       "      <td>0.001956</td>\n",
       "      <td>0.003322</td>\n",
       "      <td>0.000180</td>\n",
       "      <td>0.000306</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2792217</th>\n",
       "      <td>93422</td>\n",
       "      <td>202012</td>\n",
       "      <td>0.484472</td>\n",
       "      <td>2020-12-31</td>\n",
       "      <td>2020-12</td>\n",
       "      <td>58061.704</td>\n",
       "      <td>-0.708314</td>\n",
       "      <td>4.63</td>\n",
       "      <td>4.89</td>\n",
       "      <td>-1.50</td>\n",
       "      <td>...</td>\n",
       "      <td>0.996348</td>\n",
       "      <td>10.0</td>\n",
       "      <td>0.003311</td>\n",
       "      <td>5.315590e+07</td>\n",
       "      <td>0.001092</td>\n",
       "      <td>10.0</td>\n",
       "      <td>0.000795</td>\n",
       "      <td>0.003322</td>\n",
       "      <td>0.000385</td>\n",
       "      <td>0.001610</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2792218</th>\n",
       "      <td>93423</td>\n",
       "      <td>202012</td>\n",
       "      <td>0.109665</td>\n",
       "      <td>2020-12-31</td>\n",
       "      <td>2020-12</td>\n",
       "      <td>289771.570</td>\n",
       "      <td>-0.492846</td>\n",
       "      <td>4.63</td>\n",
       "      <td>4.89</td>\n",
       "      <td>-1.50</td>\n",
       "      <td>...</td>\n",
       "      <td>0.928619</td>\n",
       "      <td>10.0</td>\n",
       "      <td>0.003311</td>\n",
       "      <td>5.315590e+07</td>\n",
       "      <td>0.005451</td>\n",
       "      <td>10.0</td>\n",
       "      <td>0.005326</td>\n",
       "      <td>0.003322</td>\n",
       "      <td>0.000584</td>\n",
       "      <td>0.000364</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2792219 rows Ã— 22 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         PERMNO    date       RET       date2 year_month          ME  \\\n",
       "0         11404  192607  0.107323  1926-07-31    1926-07   39465.000   \n",
       "1         11674  192607  0.018657  1926-07-31    1926-07   10988.250   \n",
       "2         12319  192607  0.019653  1926-07-31    1926-07         NaN   \n",
       "3         13688  192607  0.003906  1926-07-31    1926-07         NaN   \n",
       "4         14349  192607  0.025000  1926-07-31    1926-07     512.500   \n",
       "...         ...     ...       ...         ...        ...         ...   \n",
       "2792214   93371  202012 -0.174444  2020-12-31    2020-12   23874.076   \n",
       "2792215   93373  202012 -0.401316  2020-12-31    2020-12    5910.268   \n",
       "2792216   93393  202012  0.091997  2020-12-31    2020-12  105061.600   \n",
       "2792217   93422  202012  0.484472  2020-12-31    2020-12   58061.704   \n",
       "2792218   93423  202012  0.109665  2020-12-31    2020-12  289771.570   \n",
       "\n",
       "         cumulative_returns  Mkt-RF   SMB   HML  ...      rank  decile  \\\n",
       "0                       NaN    2.96 -2.56 -2.43  ...  0.044944     1.0   \n",
       "1                       NaN    2.96 -2.56 -2.43  ...  0.067416     1.0   \n",
       "2                       NaN    2.96 -2.56 -2.43  ...  0.033708     1.0   \n",
       "3                       NaN    2.96 -2.56 -2.43  ...  0.078652     1.0   \n",
       "4                       NaN    2.96 -2.56 -2.43  ...  0.022472     1.0   \n",
       "...                     ...     ...   ...   ...  ...       ...     ...   \n",
       "2792214           -0.176182    4.63  4.89 -1.50  ...  0.930943    10.0   \n",
       "2792215           -0.844529    4.63  4.89 -1.50  ...  0.974436    10.0   \n",
       "2792216            1.189962    4.63  4.89 -1.50  ...  0.966799    10.0   \n",
       "2792217           -0.708314    4.63  4.89 -1.50  ...  0.996348    10.0   \n",
       "2792218           -0.492846    4.63  4.89 -1.50  ...  0.928619    10.0   \n",
       "\n",
       "         weights_eq           TME  weights_val  decile_lag  weights_val_lag  \\\n",
       "0          0.125000  8.615805e+04     0.458054         NaN              NaN   \n",
       "1          0.125000  8.615805e+04     0.127536         NaN              NaN   \n",
       "2          0.125000  8.615805e+04          NaN         NaN              NaN   \n",
       "3          0.125000  8.615805e+04          NaN         NaN              NaN   \n",
       "4          0.125000  8.615805e+04     0.005948         NaN              NaN   \n",
       "...             ...           ...          ...         ...              ...   \n",
       "2792214    0.003311  5.315590e+07     0.000449         9.0         0.000207   \n",
       "2792215    0.003311  5.315590e+07     0.000111         9.0         0.000070   \n",
       "2792216    0.003311  5.315590e+07     0.001976        10.0         0.001956   \n",
       "2792217    0.003311  5.315590e+07     0.001092        10.0         0.000795   \n",
       "2792218    0.003311  5.315590e+07     0.005451        10.0         0.005326   \n",
       "\n",
       "         weights_eq_lag  weighted_val_lag  weighted_eq_lag  \n",
       "0                   NaN               NaN              NaN  \n",
       "1                   NaN               NaN              NaN  \n",
       "2                   NaN               NaN              NaN  \n",
       "3                   NaN               NaN              NaN  \n",
       "4                   NaN               NaN              NaN  \n",
       "...                 ...               ...              ...  \n",
       "2792214        0.003322         -0.000036        -0.000580  \n",
       "2792215        0.003322         -0.000028        -0.001333  \n",
       "2792216        0.003322          0.000180         0.000306  \n",
       "2792217        0.003322          0.000385         0.001610  \n",
       "2792218        0.003322          0.000584         0.000364  \n",
       "\n",
       "[2792219 rows x 22 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "sortdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean monthly returns for each decile (Equal-weighted):\n",
      "decile_lag\n",
      "date    197290.563355\n",
      "1.0          1.190034\n",
      "2.0          1.208763\n",
      "3.0          1.239266\n",
      "4.0          1.358873\n",
      "5.0          1.352260\n",
      "6.0          1.415365\n",
      "7.0          1.404675\n",
      "8.0          1.496869\n",
      "9.0          1.461135\n",
      "10.0         1.496870\n",
      "dtype: float64\n",
      "Equal-weighted returns are monotonic: False\n",
      "\n",
      "Mean monthly returns for each decile (Value-weighted):\n",
      "decile_lag\n",
      "date    197290.563355\n",
      "1.0          0.794913\n",
      "2.0          0.877859\n",
      "3.0          0.933825\n",
      "4.0          1.086552\n",
      "5.0          1.017909\n",
      "6.0          1.077490\n",
      "7.0          1.072592\n",
      "8.0          1.086474\n",
      "9.0          1.147508\n",
      "10.0         1.210912\n",
      "dtype: float64\n",
      "Value-weighted returns are monotonic: False\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>decile_lag</th>\n",
       "      <th>date</th>\n",
       "      <th>1.0</th>\n",
       "      <th>2.0</th>\n",
       "      <th>3.0</th>\n",
       "      <th>4.0</th>\n",
       "      <th>5.0</th>\n",
       "      <th>6.0</th>\n",
       "      <th>7.0</th>\n",
       "      <th>8.0</th>\n",
       "      <th>9.0</th>\n",
       "      <th>10.0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>192608</td>\n",
       "      <td>2.636287</td>\n",
       "      <td>1.305056</td>\n",
       "      <td>1.072678</td>\n",
       "      <td>2.123744</td>\n",
       "      <td>4.750900</td>\n",
       "      <td>1.250389</td>\n",
       "      <td>4.635478</td>\n",
       "      <td>0.857989</td>\n",
       "      <td>5.658900</td>\n",
       "      <td>5.117244</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>192609</td>\n",
       "      <td>-0.046962</td>\n",
       "      <td>-1.772600</td>\n",
       "      <td>5.529622</td>\n",
       "      <td>-3.460822</td>\n",
       "      <td>2.180100</td>\n",
       "      <td>11.200211</td>\n",
       "      <td>-2.359089</td>\n",
       "      <td>5.895589</td>\n",
       "      <td>3.423333</td>\n",
       "      <td>-2.513922</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>192610</td>\n",
       "      <td>-1.682000</td>\n",
       "      <td>-0.367600</td>\n",
       "      <td>-2.326256</td>\n",
       "      <td>-3.408700</td>\n",
       "      <td>-5.664478</td>\n",
       "      <td>-6.245700</td>\n",
       "      <td>-0.612456</td>\n",
       "      <td>-8.164200</td>\n",
       "      <td>0.108133</td>\n",
       "      <td>-5.247100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>192611</td>\n",
       "      <td>2.702263</td>\n",
       "      <td>6.129622</td>\n",
       "      <td>2.543722</td>\n",
       "      <td>0.273367</td>\n",
       "      <td>3.335056</td>\n",
       "      <td>1.971700</td>\n",
       "      <td>-0.570867</td>\n",
       "      <td>3.513944</td>\n",
       "      <td>4.197989</td>\n",
       "      <td>1.270167</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>192612</td>\n",
       "      <td>4.222233</td>\n",
       "      <td>2.729556</td>\n",
       "      <td>2.119800</td>\n",
       "      <td>3.113567</td>\n",
       "      <td>6.702867</td>\n",
       "      <td>4.095567</td>\n",
       "      <td>0.003211</td>\n",
       "      <td>2.612078</td>\n",
       "      <td>5.493878</td>\n",
       "      <td>6.572644</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1092</th>\n",
       "      <td>202008</td>\n",
       "      <td>-1.035453</td>\n",
       "      <td>2.829020</td>\n",
       "      <td>4.504622</td>\n",
       "      <td>5.256450</td>\n",
       "      <td>5.665360</td>\n",
       "      <td>7.417315</td>\n",
       "      <td>6.304047</td>\n",
       "      <td>8.115191</td>\n",
       "      <td>3.540307</td>\n",
       "      <td>3.785530</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1093</th>\n",
       "      <td>202009</td>\n",
       "      <td>-2.668724</td>\n",
       "      <td>-3.750258</td>\n",
       "      <td>-2.318918</td>\n",
       "      <td>-2.514807</td>\n",
       "      <td>-3.191168</td>\n",
       "      <td>-3.978734</td>\n",
       "      <td>-4.225685</td>\n",
       "      <td>-3.179992</td>\n",
       "      <td>-0.746081</td>\n",
       "      <td>-1.986663</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1094</th>\n",
       "      <td>202010</td>\n",
       "      <td>1.126370</td>\n",
       "      <td>1.103624</td>\n",
       "      <td>1.930731</td>\n",
       "      <td>2.422193</td>\n",
       "      <td>2.952135</td>\n",
       "      <td>3.961857</td>\n",
       "      <td>1.949392</td>\n",
       "      <td>3.041627</td>\n",
       "      <td>0.853769</td>\n",
       "      <td>-2.691036</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1095</th>\n",
       "      <td>202011</td>\n",
       "      <td>10.412596</td>\n",
       "      <td>11.970741</td>\n",
       "      <td>14.912760</td>\n",
       "      <td>16.623207</td>\n",
       "      <td>19.789341</td>\n",
       "      <td>19.043483</td>\n",
       "      <td>20.965406</td>\n",
       "      <td>22.529429</td>\n",
       "      <td>31.129334</td>\n",
       "      <td>32.824257</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1096</th>\n",
       "      <td>202012</td>\n",
       "      <td>6.019204</td>\n",
       "      <td>5.730875</td>\n",
       "      <td>6.132773</td>\n",
       "      <td>7.131078</td>\n",
       "      <td>9.083767</td>\n",
       "      <td>9.477998</td>\n",
       "      <td>9.648125</td>\n",
       "      <td>7.888150</td>\n",
       "      <td>12.002243</td>\n",
       "      <td>13.320202</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1097 rows Ã— 11 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "decile_lag    date        1.0        2.0        3.0        4.0        5.0  \\\n",
       "0           192608   2.636287   1.305056   1.072678   2.123744   4.750900   \n",
       "1           192609  -0.046962  -1.772600   5.529622  -3.460822   2.180100   \n",
       "2           192610  -1.682000  -0.367600  -2.326256  -3.408700  -5.664478   \n",
       "3           192611   2.702263   6.129622   2.543722   0.273367   3.335056   \n",
       "4           192612   4.222233   2.729556   2.119800   3.113567   6.702867   \n",
       "...            ...        ...        ...        ...        ...        ...   \n",
       "1092        202008  -1.035453   2.829020   4.504622   5.256450   5.665360   \n",
       "1093        202009  -2.668724  -3.750258  -2.318918  -2.514807  -3.191168   \n",
       "1094        202010   1.126370   1.103624   1.930731   2.422193   2.952135   \n",
       "1095        202011  10.412596  11.970741  14.912760  16.623207  19.789341   \n",
       "1096        202012   6.019204   5.730875   6.132773   7.131078   9.083767   \n",
       "\n",
       "decile_lag        6.0        7.0        8.0        9.0       10.0  \n",
       "0            1.250389   4.635478   0.857989   5.658900   5.117244  \n",
       "1           11.200211  -2.359089   5.895589   3.423333  -2.513922  \n",
       "2           -6.245700  -0.612456  -8.164200   0.108133  -5.247100  \n",
       "3            1.971700  -0.570867   3.513944   4.197989   1.270167  \n",
       "4            4.095567   0.003211   2.612078   5.493878   6.572644  \n",
       "...               ...        ...        ...        ...        ...  \n",
       "1092         7.417315   6.304047   8.115191   3.540307   3.785530  \n",
       "1093        -3.978734  -4.225685  -3.179992  -0.746081  -1.986663  \n",
       "1094         3.961857   1.949392   3.041627   0.853769  -2.691036  \n",
       "1095        19.043483  20.965406  22.529429  31.129334  32.824257  \n",
       "1096         9.477998   9.648125   7.888150  12.002243  13.320202  \n",
       "\n",
       "[1097 rows x 11 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "sortdf.reset_index(drop = True, inplace = True)\n",
    "sortdf['weighted_val_lag'] = sortdf['weights_val_lag'] * sortdf['RET']\n",
    "sortdf['weighted_eq_lag'] = sortdf['weights_eq_lag'] * sortdf['RET']\n",
    "\n",
    "# Sum up portfolio returns\n",
    "eqports = sortdf.groupby(['date', 'decile_lag'])['weighted_eq_lag'].sum()\n",
    "eqports = eqports.unstack()\n",
    "# Missing accounting data in early years\n",
    "eqports = eqports.dropna(axis=0)\n",
    "# Match data format of FF factors\n",
    "eqports = eqports * 100\n",
    "eqports = eqports.reset_index()\n",
    "\n",
    "valports = sortdf.groupby(['date', 'decile_lag'])['weighted_val_lag'].sum()\n",
    "valports = valports.unstack()\n",
    "valports = valports.dropna(axis=0)\n",
    "valports = valports * 100\n",
    "valports = valports.reset_index()\n",
    "\n",
    "mean_monthly_returns_eq = eqports.mean(axis=0)\n",
    "mean_monthly_returns_val = valports.mean(axis=0)\n",
    "\n",
    "monotonic_eq = (mean_monthly_returns_eq.is_monotonic_increasing or\n",
    "                mean_monthly_returns_eq.is_monotonic_decreasing)\n",
    "\n",
    "monotonic_val = (mean_monthly_returns_val.is_monotonic_increasing or\n",
    "                 mean_monthly_returns_val.is_monotonic_decreasing)\n",
    "\n",
    "print(\"Mean monthly returns for each decile (Equal-weighted):\")\n",
    "print(mean_monthly_returns_eq)\n",
    "print(f\"Equal-weighted returns are monotonic: {monotonic_eq}\\n\")\n",
    "\n",
    "print(\"Mean monthly returns for each decile (Value-weighted):\")\n",
    "print(mean_monthly_returns_val)\n",
    "print(f\"Value-weighted returns are monotonic: {monotonic_val}\")\n",
    "\n",
    "eqports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Equal-Weighted Long-Short Portfolio:\n",
      "Mean Return: -0.3068365124880474\n",
      "Volatility: 7.796955525994017\n",
      "Sharpe Ratio: -0.039353374719798655\n",
      "\n",
      "Value-Weighted Long-Short Portfolio:\n",
      "Mean Return: -0.4159986823873198\n",
      "Volatility: 8.590257821440023\n",
      "Sharpe Ratio: -0.04842679824452394\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Form the long-short winners-minus-losers portfolio\n",
    "eqports['1-10'] = eqports[1.0] - eqports[10.0]\n",
    "valports['1-10'] = valports[1.0] - valports[10.0] \n",
    "\n",
    "mean_long_short_eq = eqports['1-10'].mean()\n",
    "mean_long_short_val = valports['1-10'].mean()\n",
    "\n",
    "vol_long_short_eq = eqports['1-10'].std()\n",
    "vol_long_short_val = valports['1-10'].std()\n",
    "\n",
    "sharpe_ratio_eq = mean_long_short_eq / vol_long_short_eq\n",
    "sharpe_ratio_val = mean_long_short_val / vol_long_short_val\n",
    "\n",
    "print(f\"Equal-Weighted Long-Short Portfolio:\")\n",
    "print(f\"Mean Return: {mean_long_short_eq}\")\n",
    "print(f\"Volatility: {vol_long_short_eq}\")\n",
    "print(f\"Sharpe Ratio: {sharpe_ratio_eq}\\n\")\n",
    "\n",
    "print(f\"Value-Weighted Long-Short Portfolio:\")\n",
    "print(f\"Mean Return: {mean_long_short_val}\")\n",
    "print(f\"Volatility: {vol_long_short_val}\")\n",
    "print(f\"Sharpe Ratio: {sharpe_ratio_val}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                            OLS Regression Results                            \n",
      "==============================================================================\n",
      "Dep. Variable:                   1-10   R-squared:                       0.465\n",
      "Model:                            OLS   Adj. R-squared:                  0.465\n",
      "Method:                 Least Squares   F-statistic:                     567.5\n",
      "Date:                Sun, 21 Apr 2024   Prob (F-statistic):           1.02e-90\n",
      "Time:                        23:23:14   Log-Likelihood:                -1928.3\n",
      "No. Observations:                 654   AIC:                             3861.\n",
      "Df Residuals:                     652   BIC:                             3870.\n",
      "Df Model:                           1                                         \n",
      "Covariance Type:            nonrobust                                         \n",
      "==============================================================================\n",
      "                 coef    std err          t      P>|t|      [0.025      0.975]\n",
      "------------------------------------------------------------------------------\n",
      "const          0.3822      0.182      2.097      0.036       0.024       0.740\n",
      "Mkt-RF        -0.9849      0.041    -23.823      0.000      -1.066      -0.904\n",
      "==============================================================================\n",
      "Omnibus:                      440.212   Durbin-Watson:                   1.951\n",
      "Prob(Omnibus):                  0.000   Jarque-Bera (JB):            11761.311\n",
      "Skew:                          -2.573   Prob(JB):                         0.00\n",
      "Kurtosis:                      23.128   Cond. No.                         4.45\n",
      "==============================================================================\n",
      "\n",
      "Notes:\n",
      "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n"
     ]
    }
   ],
   "source": [
    "ff3 = pd.read_csv('ff3_factors.csv')\n",
    "ff5 = pd.read_csv('ff5_factors.csv')\n",
    "#make Date into date\n",
    "ff3.rename(columns={'Date': 'date'}, inplace=True)\n",
    "ff5.rename(columns={'Date': 'date'}, inplace=True)\n",
    "ff3_merged_eq = pd.merge(eqports, ff3, on='date')\n",
    "ff3_merged_val = pd.merge(valports, ff3, on='date')\n",
    "ff5_merged_eq = pd.merge(eqports, ff5, on='date')\n",
    "ff5_merged_val = pd.merge(valports, ff5, on='date')\n",
    "\n",
    "# Estimate CAPM - equally weighted\n",
    "model1=sm.OLS(ff5_merged_eq['1-10'],\n",
    "              sm.add_constant(ff5_merged_eq[['Mkt-RF']])).fit()\n",
    "print(model1.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                            OLS Regression Results                            \n",
      "==============================================================================\n",
      "Dep. Variable:                   1-10   R-squared:                       0.567\n",
      "Model:                            OLS   Adj. R-squared:                  0.567\n",
      "Method:                 Least Squares   F-statistic:                     1436.\n",
      "Date:                Sun, 21 Apr 2024   Prob (F-statistic):          1.79e-201\n",
      "Time:                        23:23:22   Log-Likelihood:                -3455.7\n",
      "No. Observations:                1097   AIC:                             6915.\n",
      "Df Residuals:                    1095   BIC:                             6925.\n",
      "Df Model:                           1                                         \n",
      "Covariance Type:            nonrobust                                         \n",
      "==============================================================================\n",
      "                 coef    std err          t      P>|t|      [0.025      0.975]\n",
      "------------------------------------------------------------------------------\n",
      "const          0.4098      0.172      2.382      0.017       0.072       0.747\n",
      "Mkt-RF        -1.2123      0.032    -37.898      0.000      -1.275      -1.149\n",
      "==============================================================================\n",
      "Omnibus:                      306.890   Durbin-Watson:                   1.832\n",
      "Prob(Omnibus):                  0.000   Jarque-Bera (JB):             1980.108\n",
      "Skew:                          -1.124   Prob(JB):                         0.00\n",
      "Kurtosis:                       9.186   Cond. No.                         5.43\n",
      "==============================================================================\n",
      "\n",
      "Notes:\n",
      "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n"
     ]
    }
   ],
   "source": [
    "# Estimate CAPM - value weighted\n",
    "model1=sm.OLS(ff3_merged_val['1-10'],\n",
    "              sm.add_constant(ff3_merged_val[['Mkt-RF']])).fit()\n",
    "print(model1.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                            OLS Regression Results                            \n",
      "==============================================================================\n",
      "Dep. Variable:                   1-10   R-squared:                       0.699\n",
      "Model:                            OLS   Adj. R-squared:                  0.699\n",
      "Method:                 Least Squares   F-statistic:                     847.4\n",
      "Date:                Sun, 21 Apr 2024   Prob (F-statistic):          1.31e-284\n",
      "Time:                        23:23:36   Log-Likelihood:                -3149.9\n",
      "No. Observations:                1097   AIC:                             6308.\n",
      "Df Residuals:                    1093   BIC:                             6328.\n",
      "Df Model:                           3                                         \n",
      "Covariance Type:            nonrobust                                         \n",
      "==============================================================================\n",
      "                 coef    std err          t      P>|t|      [0.025      0.975]\n",
      "------------------------------------------------------------------------------\n",
      "const          0.5863      0.131      4.490      0.000       0.330       0.843\n",
      "Mkt-RF        -0.8902      0.026    -33.784      0.000      -0.942      -0.838\n",
      "SMB           -0.8209      0.043    -19.155      0.000      -0.905      -0.737\n",
      "HML           -0.3214      0.038     -8.503      0.000      -0.396      -0.247\n",
      "==============================================================================\n",
      "Omnibus:                      474.231   Durbin-Watson:                   1.838\n",
      "Prob(Omnibus):                  0.000   Jarque-Bera (JB):            10718.447\n",
      "Skew:                          -1.453   Prob(JB):                         0.00\n",
      "Kurtosis:                      18.035   Cond. No.                         5.72\n",
      "==============================================================================\n",
      "\n",
      "Notes:\n",
      "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n"
     ]
    }
   ],
   "source": [
    "# Estimate FF3 - equally weighted\n",
    "model1=sm.OLS(ff3_merged_eq['1-10'],\n",
    "              sm.add_constant(ff3_merged_eq[['Mkt-RF', 'SMB', 'HML']])).fit()\n",
    "print(model1.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                            OLS Regression Results                            \n",
      "==============================================================================\n",
      "Dep. Variable:                   1-10   R-squared:                       0.611\n",
      "Model:                            OLS   Adj. R-squared:                  0.610\n",
      "Method:                 Least Squares   F-statistic:                     571.8\n",
      "Date:                Sun, 21 Apr 2024   Prob (F-statistic):          2.23e-223\n",
      "Time:                        23:23:49   Log-Likelihood:                -3397.7\n",
      "No. Observations:                1097   AIC:                             6803.\n",
      "Df Residuals:                    1093   BIC:                             6823.\n",
      "Df Model:                           3                                         \n",
      "Covariance Type:            nonrobust                                         \n",
      "==============================================================================\n",
      "                 coef    std err          t      P>|t|      [0.025      0.975]\n",
      "------------------------------------------------------------------------------\n",
      "const          0.4922      0.164      3.007      0.003       0.171       0.813\n",
      "Mkt-RF        -1.0769      0.033    -32.605      0.000      -1.142      -1.012\n",
      "SMB           -0.5549      0.054    -10.329      0.000      -0.660      -0.449\n",
      "HML           -0.1575      0.047     -3.323      0.001      -0.250      -0.064\n",
      "==============================================================================\n",
      "Omnibus:                      277.696   Durbin-Watson:                   1.846\n",
      "Prob(Omnibus):                  0.000   Jarque-Bera (JB):             2404.387\n",
      "Skew:                          -0.909   Prob(JB):                         0.00\n",
      "Kurtosis:                      10.021   Cond. No.                         5.72\n",
      "==============================================================================\n",
      "\n",
      "Notes:\n",
      "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n"
     ]
    }
   ],
   "source": [
    "# Estimate FF3 - value weighted\n",
    "model1=sm.OLS(ff3_merged_val['1-10'],\n",
    "              sm.add_constant(ff3_merged_val[['Mkt-RF', 'SMB', 'HML']])).fit()\n",
    "print(model1.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                            OLS Regression Results                            \n",
      "==============================================================================\n",
      "Dep. Variable:                   1-10   R-squared:                       0.645\n",
      "Model:                            OLS   Adj. R-squared:                  0.642\n",
      "Method:                 Least Squares   F-statistic:                     235.0\n",
      "Date:                Sun, 21 Apr 2024   Prob (F-statistic):          6.26e-143\n",
      "Time:                        23:23:53   Log-Likelihood:                -1794.8\n",
      "No. Observations:                 654   AIC:                             3602.\n",
      "Df Residuals:                     648   BIC:                             3628.\n",
      "Df Model:                           5                                         \n",
      "Covariance Type:            nonrobust                                         \n",
      "==============================================================================\n",
      "                 coef    std err          t      P>|t|      [0.025      0.975]\n",
      "------------------------------------------------------------------------------\n",
      "const          0.1032      0.154      0.668      0.504      -0.200       0.406\n",
      "Mkt-RF        -0.7295      0.039    -18.774      0.000      -0.806      -0.653\n",
      "SMB           -0.5318      0.054     -9.923      0.000      -0.637      -0.427\n",
      "HML            0.2574      0.071      3.614      0.000       0.118       0.397\n",
      "RMW            0.7287      0.074      9.815      0.000       0.583       0.874\n",
      "CMA            0.1801      0.110      1.630      0.104      -0.037       0.397\n",
      "==============================================================================\n",
      "Omnibus:                      481.833   Durbin-Watson:                   1.888\n",
      "Prob(Omnibus):                  0.000   Jarque-Bera (JB):            15177.017\n",
      "Skew:                          -2.888   Prob(JB):                         0.00\n",
      "Kurtosis:                      25.882   Cond. No.                         5.11\n",
      "==============================================================================\n",
      "\n",
      "Notes:\n",
      "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n"
     ]
    }
   ],
   "source": [
    "# Estimate FF5 - equally weighted\n",
    "model1=sm.OLS(ff5_merged_eq['1-10'],\n",
    "              sm.add_constant(ff5_merged_eq[['Mkt-RF', 'SMB', 'HML', 'RMW', 'CMA']])).fit()\n",
    "print(model1.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                            OLS Regression Results                            \n",
      "==============================================================================\n",
      "Dep. Variable:                   1-10   R-squared:                       0.601\n",
      "Model:                            OLS   Adj. R-squared:                  0.598\n",
      "Method:                 Least Squares   F-statistic:                     194.9\n",
      "Date:                Sun, 21 Apr 2024   Prob (F-statistic):          1.48e-126\n",
      "Time:                        23:23:57   Log-Likelihood:                -1952.4\n",
      "No. Observations:                 654   AIC:                             3917.\n",
      "Df Residuals:                     648   BIC:                             3944.\n",
      "Df Model:                           5                                         \n",
      "Covariance Type:            nonrobust                                         \n",
      "==============================================================================\n",
      "                 coef    std err          t      P>|t|      [0.025      0.975]\n",
      "------------------------------------------------------------------------------\n",
      "const         -0.1417      0.196     -0.721      0.471      -0.527       0.244\n",
      "Mkt-RF        -0.8091      0.049    -16.361      0.000      -0.906      -0.712\n",
      "SMB           -0.5095      0.068     -7.471      0.000      -0.643      -0.376\n",
      "HML            0.2518      0.091      2.778      0.006       0.074       0.430\n",
      "RMW            0.8103      0.094      8.576      0.000       0.625       0.996\n",
      "CMA            0.6499      0.141      4.623      0.000       0.374       0.926\n",
      "==============================================================================\n",
      "Omnibus:                      149.889   Durbin-Watson:                   1.842\n",
      "Prob(Omnibus):                  0.000   Jarque-Bera (JB):              848.925\n",
      "Skew:                          -0.892   Prob(JB):                    4.55e-185\n",
      "Kurtosis:                       8.289   Cond. No.                         5.11\n",
      "==============================================================================\n",
      "\n",
      "Notes:\n",
      "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n"
     ]
    }
   ],
   "source": [
    "# Estimate FF5 - value weighted\n",
    "model1=sm.OLS(ff5_merged_val['1-10'],\n",
    "              sm.add_constant(ff5_merged_val[['Mkt-RF', 'SMB', 'HML', 'RMW', 'CMA']])).fit()\n",
    "print(model1.summary())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Part e"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "One option is diversification, which involves spreading investments across various financial instruments, industries, and other categories to optimize potential return and limit risk. Since different assets perform differently in different market and economic conditions, a diversified portfolio helps to mitigate risk and volatility. Another option is hedging, which we can do by taking a short position in the futures market that bets against your current position. This way, if your stocks do fall in value, the short position in futures should generate profits to offset the loss. "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
